{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, './..')\n",
    "sys.path.insert(0, '../data')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import matplotlib.gridspec as gridspec\n",
    "import proplot as pplt\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from models import model, eval\n",
    "import plots as pl\n",
    "from utils import dev, load_data, classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "model_natural = model.madry_diff()\n",
    "model_natural.load_state_dict(torch.load('../models/natural_0.pt', map_location=torch.device(dev())))\n",
    "model_natural.to(dev())\n",
    "model_natural.eval()\n",
    "\n",
    "model_robust = model.madry_diff()\n",
    "model_robust.load_state_dict(torch.load('../models/robust_0.pt', map_location=torch.device(dev())))\n",
    "model_robust.to(dev())\n",
    "model_robust.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "# load data\n",
    "data = np.load(f'../data/natural_{seed}.npy', allow_pickle=True).item()\n",
    "advs = data['advs']\n",
    "pert_lengths = data['pert_lengths']\n",
    "classes = data['adv_class']\n",
    "dirs = data['dirs']\n",
    "images = data['images']\n",
    "labels = data['labels']\n",
    "pert_lengths = data['pert_lengths']\n",
    "\n",
    "data = np.load(f'../data/robust_{seed}.npy', allow_pickle=True).item()\n",
    "advs_madry = data['advs']\n",
    "pert_lengths_madry = data['pert_lengths']\n",
    "classes_madry = data['adv_class']\n",
    "dirs_madry = data['dirs']\n",
    "images_madry = data['images']\n",
    "labels_madry = data['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check seed consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [0, 1, 2, 3]\n",
    "model_type = 'natural'\n",
    "#data = np.load('../data/natural0.npy', allow_pickle=True).item()\n",
    "#images = data['images']\n",
    "#labels = data['labels']\n",
    "#n_advs = np.zeros((3,len(images)))\n",
    "n_advs = []\n",
    "for i, model_id in enumerate(seeds):\n",
    "    # load data\n",
    "    data = np.load(f'../data/{model_type}_{model_id}.npy', allow_pickle=True).item()\n",
    "    advs = data['advs']\n",
    "    pert_lengths = data['pert_lengths']\n",
    "    classes = data['adv_class']\n",
    "    dirs = data['dirs']\n",
    "    images = data['images']\n",
    "    labels = data['labels']\n",
    "    pert_lengths = data['pert_lengths']\n",
    "    n_advs.append(15-np.isnan(pert_lengths).sum(1))\n",
    "n_advs = np.stack(n_advs, axis=0)\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.hist(n_advs.T, alpha=0.5, bins=16, range=(-0.5,15.5))\n",
    "\n",
    "print(f'mean number of adversarial directions = {np.mean(np.std(n_advs,axis=0))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(n_advs.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot grid of adversarial examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_n = 0\n",
    "fig , ax = pl.plot_advs(advs[img_n], orig=images[img_n], classes=classes[img_n], orig_class=labels[img_n], n=5,vmin=0,vmax=1)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5, 6, squeeze=False, figsize=(9,8))\n",
    "for j in range(5):\n",
    "    orig = np.reshape(images[j*50], [28, 28])\n",
    "    if j == 0:\n",
    "        ax[j, 0].set_title('original', fontsize=18)\n",
    "    ax[j, 0].imshow(orig, cmap='gray', vmin=0, vmax=1)\n",
    "    ax[j, 0].set_xticks([])\n",
    "    ax[j, 0].set_yticks([])\n",
    "    ax[j, 0].set_xlabel(str(labels[j*50]), fontdict={'fontsize': 18})\n",
    "\n",
    "    for i, a in enumerate(advs[j*50,:5]):\n",
    "        if j==0:\n",
    "            ax[j, i+1].set_title('Adv. ' + str(i + 1), fontsize=18)\n",
    "        ax[j, i+1].set_xlabel('\\u279E ' + str(int(classes[j*50,i])), fontdict={'fontsize': 18})\n",
    "        ax[j, i+1].imshow(a.reshape([28, 28]), cmap='gray', vmin=0, vmax=1)\n",
    "        ax[j, i+1].set_xticks([])\n",
    "        ax[j, i+1].set_yticks([])\n",
    "plt.subplots_adjust(hspace=0.3, left=0, right=1, bottom=0.05, top=0.95)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot madry and natural adversarial examples in one figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "for i in range(5):\n",
    "    plt.subplot(3,5,1+i)\n",
    "    plt.title('Orig. class ' + str(labels[i*50]))\n",
    "    plt.imshow(np.reshape(images[i*50], [28,28]), cmap='gray', vmin=0, vmax=1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if i == 0:\n",
    "        plt.ylabel(\"Original Image\")\n",
    "    \n",
    "    plt.subplot(3,5,6+i)\n",
    "    plt.title('Adv. class ' + str(classes[i*50,0]))\n",
    "    plt.imshow(np.reshape(advs[i*50,0], [28,28]), cmap='gray', vmin=0, vmax=1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if i == 0:\n",
    "        plt.ylabel(\"Natural CNN\")\n",
    "\n",
    "    plt.subplot(3,5,11+i)\n",
    "    plt.title('Adv. class ' + str(classes_madry[i*50,0]))\n",
    "    plt.imshow(np.reshape(advs_madry[i*50,0], [28,28]), cmap='gray', vmin=0, vmax=1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if i == 0:\n",
    "        plt.ylabel(\"Madry CNN\")\n",
    "plt.suptitle('Adversarials of non-robust and robust models')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perturbation Length comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot with all adversarials included\n",
    "fig , ax = pl.plot_pert_lengths([pert_lengths, pert_lengths_madry],  n=15, labels=['naturally trained','adversarially trained'], ord=2)\n",
    "fig.set_figheight(8)\n",
    "fig.set_figwidth(12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only samples with at least n adversarials included\n",
    "n=8\n",
    "\n",
    "p_robust = pert_lengths_madry[np.invert(np.isnan(pert_lengths_madry)).sum(-1)>=n]\n",
    "p_natural = pert_lengths[np.invert(np.isnan(pert_lengths)).sum(-1)>=n]\n",
    "        \n",
    "fig , ax = pl.plot_pert_lengths([p_natural,p_robust],  n=n, labels=['naturally trained','adversarially trained'], ord=2)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot variation of target classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_ = classes_madry\n",
    "pert_lengths_ = pert_lengths_madry\n",
    "\n",
    "mask_idx = np.invert(np.isnan(pert_lengths)).sum(1)>1\n",
    "classes_[np.isnan(pert_lengths_)]=np.nan\n",
    "classes_ = classes_[mask_idx]\n",
    "labels_ = labels[mask_idx]\n",
    "fig, ax = pl.plot_var_hist(classes_, labels_, title='Robust CNN', with_colors = True)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(7)\n",
    "plt.ylim(0,.85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_idx = np.invert(np.isnan(pert_lengths)).sum(1) > 1\n",
    "advs_frac_found = np.zeros((2, 10, 10)) # [natural/robust, fraction_label_to, gt_label]\n",
    "advs_per_class = np.zeros((2, 10))\n",
    "advs_num_classes = np.zeros((2, 10))\n",
    "for i, (classes_, pert_lengths_) in enumerate(zip([classes, classes_madry], [pert_lengths, pert_lengths_madry])):\n",
    "    classes_[np.isnan(pert_lengths_)] = np.nan\n",
    "    classes_ = classes_[mask_idx]\n",
    "    labels_ = labels[mask_idx]\n",
    "    for l in range(10):\n",
    "        var = np.mean(np.array([(len(np.unique(x[~np.isnan(x)]))-1)/(len(x[~np.isnan(x)])-1) for x in classes_[labels == l]]))\n",
    "        advs_num_classes[i, l] = var\n",
    "        u, c = np.unique(classes_[labels_ == l], return_counts=True)\n",
    "        c = c[~np.isnan(u)]\n",
    "        u = u[~np.isnan(u)]\n",
    "        advs_frac_found[i, u.astype(int), l] = c / np.sum(c)\n",
    "        p = pert_lengths_[labels_ == l]\n",
    "        advs_per_class[i, l] = np.mean(np.invert(np.isnan(p)).sum(1))\n",
    "#print('natural data sum per class:\\n'+'\\n'.join([str(i) + ' : ' + str(advs_frac_found[0, :, l].sum()) for l in range (10)]))\n",
    "#print('\\nrobust data sum per class:\\n'+'\\n'.join([str(i) + ' : ' + str(advs_frac_found[1, :, l].sum()) for l in range (10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['Natural', 'Robust']\n",
    "colors = ['blue', 'orange', 'green', 'purple', 'red',\n",
    "          'brown', 'grey', 'pink', 'cyan', 'olive']\n",
    "plot_labels = [str(i) for i in range(10)]\n",
    "wspace = ([0.0, 10.0,]*5)[:-1]\n",
    "fig, axs = pplt.subplots(nrows=2, ncols=10, wspace=wspace)\n",
    "ax_idx = 0\n",
    "for l in range(10): # count over each label\n",
    "    for i in range(2): # show each model per label\n",
    "        patches, texts = axs[ax_idx].pie(advs_frac_found[i, :, l], cycle=colors, startangle=90, normalize=True)\n",
    "        axs[ax_idx].format(title=f'{titles[i]} {l:01d}')\n",
    "        ax_idx += 1\n",
    "axs[0].legend(patches, labels=plot_labels, loc='upper left', ncols=1)\n",
    "pplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advs_per_class = np.zeros(10)\n",
    "for l in range(10):\n",
    "    p = pert_lengths[labels==l]\n",
    "    advs_per_class[l] = np.mean(np.invert(np.isnan(p)).sum(1))\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.bar(range(10), advs_per_class)\n",
    "plt.xticks(np.arange(0,10))\n",
    "plt.xlabel('original class label')\n",
    "plt.ylabel('mean number of directions found')\n",
    "plt.title('Natural Model')\n",
    "plt.ylim(0,25)\n",
    "plt.show()\n",
    "# print(np.mean(advs_per_class),np.mean(np.invert(np.isnan(pert_lengths)).sum(1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance to decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = 8\n",
    "n_samples = 100\n",
    "seed = 0\n",
    "dists = [np.load(f'../data/distance_to_boundary_natural_{seed}.npz')['data'],\n",
    "         np.load(f'../data/distance_to_boundary_robust_{seed}.npz')['data']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "mean_dists = np.nanmean(dists[0],axis=-1)\n",
    "mask = ~np.isnan(mean_dists)\n",
    "filtered_data = [d[m] for d, m in zip(mean_dists.T, mask.T)]\n",
    "ax.boxplot(filtered_data)\n",
    "ax.plot(np.arange(1,9),np.nanmean(pert_lengths[np.invert(np.isnan(pert_lengths)).sum(-1)>8,:8], axis=0), 'b.')\n",
    "plt.xlabel('dimension of adversarial space')\n",
    "plt.ylabel('mean distance to decision boundary')\n",
    "plt.show()\n",
    "# dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(2,9),np.mean(np.isnan(dists[0]).sum(-1),axis=0)[1:]/n_samples,'k.')\n",
    "plt.xlabel('dimension of adversarial space')\n",
    "plt.ylabel('rate of out of bounds samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['blue', 'orange']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "for i, color in enumerate(colors):\n",
    "    boxprops = dict(color=color, linewidth=1.5, alpha=0.7)\n",
    "    whiskerprops = dict(color=color, alpha=0.7)\n",
    "    capprops = dict(color=color, alpha=0.7)\n",
    "    medianprops = dict(linestyle=None, linewidth=0)\n",
    "    meanpointprops = dict(marker='o', markeredgecolor='black',\n",
    "                          markerfacecolor=color)\n",
    "\n",
    "    mean_dists = np.nanmean(dists[i], axis=-1)\n",
    "    mask = ~np.isnan(mean_dists)\n",
    "    filtered_data = [d[m] for d, m in zip(mean_dists.T, mask.T)]\n",
    "    ax.boxplot(filtered_data, whis=[10,90], showfliers=False, showmeans=False, boxprops=boxprops, \n",
    "              whiskerprops=whiskerprops, capprops=capprops, meanprops=meanpointprops,\n",
    "              medianprops=medianprops)\n",
    "    if i == 0:\n",
    "        lengths = pert_lengths\n",
    "    else:\n",
    "        lengths = pert_lengths_madry\n",
    "    x = np.arange(1, 9)\n",
    "    y = lengths[np.invert(np.isnan(lengths)).sum(-1)>8, :8]\n",
    "    ax.scatter(x, np.nanmean(y, axis=0), color=color, marker='.')\n",
    "ax.set_xlabel('dimension of adversarial space')\n",
    "ax.set_ylabel('mean distance to decision boundary')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['Natural', 'Robust']\n",
    "colors = ['blue', 'orange', 'green', 'purple', 'red',\n",
    "          'brown', 'grey', 'pink', 'cyan', 'olive']\n",
    "plot_labels = [str(i) for i in range(10)]\n",
    "\n",
    "bar_width = 0.35\n",
    "x = np.arange(len(plot_labels))\n",
    "\n",
    "fig = plt.figure()\n",
    "outer_gs = gridspec.GridSpec(nrows=2, ncols=3, figure=fig, hspace=0.5, wspace=0.5)\n",
    "\n",
    "\n",
    "ax0 = fig.add_subplot(outer_gs[0, 0])\n",
    "ax0.bar(range(10), advs_per_class[0,:])\n",
    "\n",
    "ax1 = fig.add_subplot(outer_gs[0, 1])\n",
    "ax1.bar(range(10), advs_per_class[0,:])\n",
    "\n",
    "ax_num_classes = fig.add_subplot(outer_gs[1, 0])\n",
    "ax_num_classes.bar(x-bar_width/2, advs_num_classes[0, :], bar_width, color='blue')\n",
    "ax_num_classes.bar(x+bar_width/2, advs_num_classes[1, :], bar_width, color='orange')\n",
    "ax_num_classes.set_xlabel('original class label')\n",
    "ax_num_classes.set_ylabel('mean number of adversarial classes')\n",
    "ax_num_classes.set_xticks(range(10))\n",
    "ax_num_classes.set_ylim([0,1])\n",
    "\n",
    "ax_dir_found = fig.add_subplot(outer_gs[1, 1])\n",
    "ax_dir_found.bar(x-bar_width/2, advs_per_class[0, :], bar_width, color='blue')\n",
    "ax_dir_found.bar(x+bar_width/2, advs_per_class[1, :], bar_width, color='orange')\n",
    "ax_dir_found.set_xticks(np.arange(0,10), minor=False)\n",
    "ax_dir_found.set_xticks([], minor=True)\n",
    "ax_dir_found.set_xlabel('original class label')\n",
    "ax_dir_found.set_ylabel('mean number of directions found')\n",
    "ax_dir_found.set_ylim(0,25)\n",
    "\n",
    "pie_gs = gridspec.GridSpecFromSubplotSpec(nrows=2, ncols=5, subplot_spec=outer_gs[0,2], hspace=-1)\n",
    "pie_idx = 0\n",
    "for l in range(10): # label index\n",
    "    pie_inner_gs = gridspec.GridSpecFromSubplotSpec(nrows=1, ncols=2, subplot_spec=pie_gs[pie_idx], wspace=0.01)\n",
    "    for i in range(2):\n",
    "        ax = fig.add_subplot(pie_inner_gs[i])\n",
    "        patches, texts = ax.pie(advs_frac_found[i, :, l], colors=colors, startangle=90, normalize=True)\n",
    "        #ax.set_title(f'{l}')\n",
    "    pie_idx += 1\n",
    "\n",
    "plt.suptitle(\"Figure 2\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Space Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_n in [0,50,100,150,200,250,300,350,400,450]:\n",
    "    orig = images[img_n]\n",
    "    adv1 = advs_madry[img_n,0]\n",
    "    adv2 = advs_madry[img_n,1]\n",
    "    model_ = model_robust\n",
    "    pl.plot_dec_space(orig, adv1, adv2, model_, show_legend=True, show_advs=True, overlay_inbounds=True)\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,3)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
