{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, './..')\n",
    "sys.path.insert(0, '../data')\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as mpatches\n",
    "import proplot as pplt\n",
    "import pandas as pd\n",
    "import dill\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from models import eval\n",
    "from models import model as model_loader\n",
    "import plots as pl\n",
    "from utils import dev, load_data, classification, make_orth_basis\n",
    "from robustness1.datasets import CIFAR\n",
    "\n",
    "sys.path.insert(0, './../../')\n",
    "\n",
    "import response_contour_analysis.utils.model_handling as model_utils\n",
    "import response_contour_analysis.utils.dataset_generation as data_utils\n",
    "import response_contour_analysis.utils.histogram_analysis as hist_utils\n",
    "import response_contour_analysis.utils.principal_curvature as curve_utils\n",
    "import response_contour_analysis.utils.plotting as plot_utils\n",
    "\n",
    "# check device\n",
    "print(dev())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hess_params = dict()\n",
    "hess_params['hessian_num_pts'] = 1.0e4\n",
    "hess_params['hessian_lr'] = 1e-4\n",
    "hess_params['hessian_random_walk'] = False\n",
    "hess_params['return_points'] = False\n",
    "hess_params['lr_decay'] = False#True\n",
    "num_iters = 2 # for paired image boundary search\n",
    "num_steps_per_iter = 100 # for paired image boundary search\n",
    "buffer_portion = 0.25\n",
    "num_eps = 1000\n",
    "batch_size = 1000\n",
    "num_images = 50#labels_nat.size\n",
    "hess_radius_mult = 0.7 # times the min adv perturbation length\n",
    "num_advs = 8\n",
    "autodiff = True\n",
    "load = False\n",
    "num_hessian_tests = 0#10\n",
    "\n",
    "plot_settings = {\n",
    "        \"text.usetex\": True,\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.size\": 8,\n",
    "        \"axes.formatter.use_mathtext\":True,\n",
    "}\n",
    "pplt.rc.update(plot_settings)\n",
    "mpl.rcParams.update(plot_settings)\n",
    "\n",
    "figwidth = '13.968cm'\n",
    "figwidth_inch = 5.50107 \n",
    "dpi = 600\n",
    "model_types = ['Naturally trained', 'Adversarially trained']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tab_name_to_hex(tab): \n",
    "    conv_table = {\n",
    "        \"tab:blue\": \"#1f77b4\",\n",
    "        \"tab:orange\": \"#ff7f0e\",\n",
    "        \"tab:green\": \"#2ca02c\",\n",
    "        \"tab:red\": \"#d62728\",\n",
    "        \"tab:purple\": \"#9467bd\",\n",
    "        \"tab:brown\": \"#8c564b\",\n",
    "        \"tab:pink\": \"#e377c2\",\n",
    "        \"tab:gray\": \"#7f7f7f\",\n",
    "        \"tab:grey\": \"#7f7f7f\",\n",
    "        \"tab:olive\": \"#bcbd22\",\n",
    "        \"tab:cyan\": \"#17becf\",\n",
    "    }\n",
    "    return conv_table[tab.lower()]\n",
    "\n",
    "plot_colors = [tab_name_to_hex('tab:blue'), tab_name_to_hex('tab:red')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data & models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "# load data\n",
    "data_natural = np.load(f'../data/cifar_natural_diff.npy', allow_pickle=True).item()\n",
    "advs_nat = data_natural['advs']\n",
    "pert_lengths_nat = data_natural['pert_lengths']\n",
    "classes_nat = data_natural['adv_class']\n",
    "dirs_nat = data_natural['dirs']\n",
    "images_nat = data_natural['images']\n",
    "labels_nat = data_natural['labels']\n",
    "\n",
    "data_madry = np.load(f'../data/cifar_robust_diff.npy', allow_pickle=True).item()\n",
    "advs_madry = data_madry['advs']\n",
    "pert_lengths_madry = data_madry['pert_lengths']\n",
    "classes_madry = data_madry['adv_class']\n",
    "dirs_madry = data_madry['dirs']\n",
    "images_madry = data_madry['images']\n",
    "labels_madry = data_madry['labels']\n",
    "\n",
    "cifar_labels = ['airplane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_pert_lengths_nat = pert_lengths_nat[:, :num_advs]\n",
    "sub_pert_lengths_madry = pert_lengths_madry[:, :num_advs]\n",
    "mean_pert_lengths = np.mean([sub_pert_lengths_nat[np.isfinite(sub_pert_lengths_nat)].mean(),\n",
    "                             sub_pert_lengths_madry[np.isfinite(sub_pert_lengths_madry)].mean()])\n",
    "min_pert_lengths = np.min([sub_pert_lengths_nat[np.isfinite(sub_pert_lengths_nat)].min(),\n",
    "                             sub_pert_lengths_madry[np.isfinite(sub_pert_lengths_madry)].min()])\n",
    "hess_params['hessian_dist'] = min_pert_lengths * hess_radius_mult # radius around the target image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "ds = CIFAR('../data/cifar-10-batches-py')\n",
    "classifier_model = ds.get_model('resnet50', False)\n",
    "model_natural = model_loader.cifar_pretrained(classifier_model, ds)\n",
    "\n",
    "resume_path = '../models/nat_diff.pt'\n",
    "checkpoint = torch.load(resume_path, pickle_module=dill, map_location=torch.device(dev()))\n",
    "\n",
    "state_dict_path = 'model'\n",
    "if not ('model' in checkpoint):\n",
    "    state_dict_path = 'state_dict'\n",
    "sd = checkpoint[state_dict_path]\n",
    "sd = {k[len('module.'):]: v for k, v in sd.items()}\n",
    "model_natural.load_state_dict(sd)\n",
    "model_natural.to(dev())\n",
    "model_natural.double()\n",
    "model_natural.eval()\n",
    "\n",
    "classifier_model = ds.get_model('resnet50', False)\n",
    "model_madry = model_loader.cifar_pretrained(classifier_model, ds)\n",
    "\n",
    "resume_path = '../models/rob_diff.pt'\n",
    "checkpoint = torch.load(resume_path, pickle_module=dill, map_location=torch.device(dev()))\n",
    "\n",
    "state_dict_path = 'model'\n",
    "if not ('model' in checkpoint):\n",
    "    state_dict_path = 'state_dict'\n",
    "sd = checkpoint[state_dict_path]\n",
    "sd = {k[len('module.'):]:v for k,v in sd.items()}\n",
    "model_madry.load_state_dict(sd)\n",
    "model_madry.to(dev())\n",
    "model_madry.double()\n",
    "model_madry.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torchify(img):\n",
    "    output = torch.from_numpy(img).type(torch.DoubleTensor).to(dev()) # always autodiff\n",
    "    output.requires_grad = True\n",
    "    return output\n",
    "\n",
    "\n",
    "def get_paired_boundary_image(model, origin, alt_image, num_steps_per_iter, num_iters):\n",
    "    input_shape = (1,)+origin.shape\n",
    "    def find_pert(image_line):\n",
    "        correct_lbl = torch.argmax(model(torchify(image_line[0, ...].reshape(input_shape))))\n",
    "        pert_lbl = correct_lbl.clone()\n",
    "        step_idx = 1 # already know the first one\n",
    "        while pert_lbl == correct_lbl:\n",
    "            pert_image = image_line[step_idx, ...]\n",
    "            pert_lbl = torch.argmax(model(torchify(pert_image.reshape(input_shape))))\n",
    "            step_idx += 1\n",
    "        return step_idx-1, pert_image\n",
    "    image_line = np.linspace(origin.reshape(-1), alt_image.reshape(-1), num_steps_per_iter)\n",
    "    for search_iter in range(num_iters):\n",
    "        step_idx, pert_image = find_pert(image_line)\n",
    "        image_line = np.linspace(image_line[step_idx - 1, ...], image_line[step_idx, ...], num_steps_per_iter)\n",
    "    delta_image = origin.reshape(-1) - pert_image\n",
    "    pert_length = np.linalg.norm(delta_image)\n",
    "    direction = delta_image / pert_length\n",
    "    return pert_image.reshape(origin.shape), direction, pert_length\n",
    "\n",
    "\n",
    "def generate_paired_dict(data_dict, model, num_images, num_advs):\n",
    "    image_shape = data_dict['images'].shape[1:]\n",
    "    num_pixels = int(np.prod(image_shape))\n",
    "    images = np.zeros((num_images,) + image_shape)\n",
    "    labels = np.zeros((num_images), dtype=np.int)\n",
    "    dirs = np.zeros((num_images, num_advs, 1, num_pixels))\n",
    "    advs = np.zeros((num_images, num_advs, 1, num_pixels))\n",
    "    pert_lengths = np.zeros((num_images, num_advs))\n",
    "    adv_class = np.zeros((num_images, num_advs))\n",
    "    #model_predictions = torch.argmax(model(torchify(data_dict['images'])), dim=1).detach().cpu().numpy()\n",
    "    batch_size = 10\n",
    "    image_splits = torch.split(torchify(data_dict['images']), batch_size)\n",
    "    model_predictions = []\n",
    "    for batch_idx, batch in enumerate(image_splits):\n",
    "        model_predictions.append(torch.argmax(model(batch), dim=1).detach().cpu().numpy())\n",
    "    model_predictions = np.stack(model_predictions, axis=0).reshape((len(model_predictions)*batch_size,) + model_predictions[0].shape[1:])\n",
    "    valid_indices = []\n",
    "    for image_idx in range(data_dict['images'].shape[0]):\n",
    "        if model_predictions[image_idx] == data_dict['labels'][image_idx]:\n",
    "            valid_indices.append(image_idx)\n",
    "    origin_indices = np.random.choice(valid_indices, size=num_images, replace=False)\n",
    "    for image_idx, origin_idx in enumerate(origin_indices):\n",
    "        images[image_idx, ...] = data_dict['images'][origin_idx, ...]\n",
    "        labels[image_idx] = data_dict['labels'][origin_idx]\n",
    "        shuffled_valid_indices = np.random.choice(valid_indices, size=len(valid_indices), replace=False)\n",
    "        alt_indices = [idx for idx, alt_class in zip(shuffled_valid_indices, data_dict['labels'][shuffled_valid_indices]) if alt_class != labels[image_idx]]\n",
    "        for dir_idx, alt_idx in enumerate(alt_indices[:num_advs]):\n",
    "            alt_image = data_dict['images'][alt_idx, ...]\n",
    "            boundary_image, boundary_dir, pert_length = get_paired_boundary_image(\n",
    "                model, images[image_idx, ...], alt_image, num_steps_per_iter, num_iters)\n",
    "            dirs[image_idx, dir_idx, ...] = boundary_dir.reshape(1, -1)\n",
    "            advs[image_idx, dir_idx, ...] = boundary_image.reshape(1, -1)\n",
    "            adv_class[image_idx,  dir_idx] = torch.argmax(model(torchify(boundary_image[None, ...]))).item()\n",
    "            pert_lengths[image_idx, dir_idx] =  pert_length\n",
    "    output_dict = {}\n",
    "    output_dict['images'] = images\n",
    "    output_dict['labels'] = labels\n",
    "    output_dict['dirs'] = dirs\n",
    "    output_dict['advs'] = advs\n",
    "    output_dict['adv_class'] = adv_class\n",
    "    output_dict['pert_lengths'] = pert_lengths\n",
    "    return output_dict\n",
    "\n",
    "\n",
    "def paired_activation(model, image, neuron1, neuron2):\n",
    "    if not image.requires_grad:\n",
    "        image.requires_grad = True\n",
    "    model.zero_grad()\n",
    "    activation1 = model_utils.unit_activation(model, image, neuron1, compute_grad=True)\n",
    "    activation2 = model_utils.unit_activation(model, image, neuron2, compute_grad=True)\n",
    "    activation_difference = activation1 - activation2\n",
    "    return activation_difference\n",
    "\n",
    "\n",
    "def paired_activation_and_gradient(model, image, neuron1, neuron2):\n",
    "    activation_difference = paired_activation(model, image, neuron1, neuron2)\n",
    "    grad = torch.autograd.grad(activation_difference, image)[0]\n",
    "    return activation_difference, grad\n",
    "\n",
    "\n",
    "def get_curvature(condition_zip, num_images, num_advs, num_eps, batch_size, buffer_portion, autodiff=False):\n",
    "    \"\"\"\n",
    "    A note on the gradient of the difference in activations:\n",
    "        The gradient points in the direction of the origin from the boundary image.\n",
    "        Therefore, for large enough eps, origin - eps * grad/|grad| will reach the boundary; and boundary + eps * grad/|grad| will reach the origin \n",
    "    \"\"\"\n",
    "    models, model_data = zip(*condition_zip)\n",
    "    num_models = len(models)\n",
    "    image_shape = model_data[0]['images'][0, ...][None, ...].shape\n",
    "    image_size = np.prod(image_shape)\n",
    "    num_dims = image_size - 1 #removes normal direction\n",
    "    shape_operators = np.zeros((num_models, num_images, num_advs, num_dims, num_dims))\n",
    "    principal_curvatures = np.zeros((num_models, num_images, num_advs, num_dims))\n",
    "    principal_directions = np.zeros((num_models, num_images, num_advs, image_size, num_dims))\n",
    "    origin_indices = np.zeros((num_models, num_images), dtype=np.int)\n",
    "    for model_idx, (model_, data_)  in enumerate(zip(models, model_data)):\n",
    "        model_predictions = torch.argmax(model_(torchify(data_['images'])), dim=1).detach().cpu().numpy()\n",
    "        valid_indices = [] # Need to ensure that all images are correctly labeled & have valid adversarial examples\n",
    "        for image_idx in range(data_['images'].shape[0]):\n",
    "            if model_predictions[image_idx] == data_['labels'][image_idx]: # correctly labeled\n",
    "                if np.all(np.isfinite(data_['pert_lengths'][image_idx, :num_advs])): # enough adversaries found\n",
    "                    valid_indices.append(image_idx)\n",
    "        origin_indices[model_idx, :] = np.random.choice(valid_indices, size=num_images, replace=False)\n",
    "        pbar = tqdm(total=num_advs*num_images, leave=False)\n",
    "        for image_idx, origin_idx in enumerate(list(origin_indices[model_idx, :])):\n",
    "            clean_lbl = int(data_['labels'][origin_idx])\n",
    "            for adv_idx in range(num_advs):\n",
    "                boundary_image = get_paired_boundary_image(\n",
    "                    model=model_,\n",
    "                    origin=data_['images'][origin_idx, ...],\n",
    "                    alt_image=data_['advs'][origin_idx, adv_idx, ...],\n",
    "                    num_steps_per_iter=num_steps_per_iter,\n",
    "                    num_iters=num_iters\n",
    "                )[0]\n",
    "                adv_lbl = int(data_['adv_class'][origin_idx, adv_idx])\n",
    "                if autodiff:\n",
    "                    def func(x):\n",
    "                        acts_diff = paired_activation(model_, x, clean_lbl, adv_lbl)\n",
    "                        return acts_diff\n",
    "                    hessian = torch.autograd.functional.hessian(func, torchify(boundary_image[None,...]))\n",
    "                    hessian = hessian.reshape((int(boundary_image.size), int(boundary_image.size)))\n",
    "                else:\n",
    "                    def func(x):\n",
    "                        acts_diff, grad = paired_activation_and_gradient(model_, x, clean_lbl, adv_lbl)\n",
    "                        return acts_diff, grad\n",
    "                    hessian = curve_utils.sr1_hessian(\n",
    "                        func, torchify(boundary_image[None, ...]),\n",
    "                        distance=hess_params['hessian_dist'],\n",
    "                        n_points=hess_params['hessian_num_pts'],\n",
    "                        random_walk=hess_params['hessian_random_walk'],\n",
    "                        learning_rate=hess_params['hessian_lr'],\n",
    "                        return_points=False,\n",
    "                        progress=False)\n",
    "                activation, gradient = paired_activation_and_gradient(model_, torchify(boundary_image[None, ...]), clean_lbl, adv_lbl)\n",
    "                gradient = gradient.reshape(-1)\n",
    "                curvature = curve_utils.local_response_curvature_isoresponse_surface(gradient, hessian)\n",
    "                shape_operators[model_idx, image_idx, adv_idx, ...] = curvature[0].detach().cpu().numpy()\n",
    "                principal_curvatures[model_idx, image_idx, adv_idx, :] = curvature[1].detach().cpu().numpy()\n",
    "                principal_directions[model_idx, image_idx, adv_idx, ...] = curvature[2].detach().cpu().numpy()\n",
    "                pbar.update(1)\n",
    "        pbar.close()\n",
    "    return shape_operators, principal_curvatures, principal_directions, origin_indices\n",
    "\n",
    "\n",
    "def get_hessian_error(model, origin, clean_lbl, adv_lbl, abscissa, ordinate, hess_params):\n",
    "    def act_func(x):\n",
    "        acts_diff = paired_activation(model, x, clean_lbl, adv_lbl)\n",
    "        return acts_diff\n",
    "    def act_grad_func(x):\n",
    "        acts_diff, grad = paired_activation_and_gradient(model, x, clean_lbl, adv_lbl)\n",
    "        return acts_diff, grad\n",
    "    origin.requires_grad = True\n",
    "    sr1_hessian = curve_utils.sr1_hessian(\n",
    "        act_grad_func, origin,\n",
    "        distance=hess_params['hessian_dist'],\n",
    "        n_points=hess_params['hessian_num_pts'],\n",
    "        random_walk=hess_params['hessian_random_walk'],\n",
    "        learning_rate=hess_params['hessian_lr'],\n",
    "        return_points=False,\n",
    "        progress=True)\n",
    "    autodiff_hessian = torch.autograd.functional.hessian(act_func, origin)\n",
    "    autodiff_hessian = autodiff_hessian.reshape((int(origin.numel()), int(origin.numel())))\n",
    "    n_x_samples = 10\n",
    "    n_y_samples = 100\n",
    "    x = np.linspace(-hess_params['hessian_dist']/2, hess_params['hessian_dist']/2, n_x_samples)\n",
    "    y = np.linspace(-hess_params['hessian_dist']*1.25, hess_params['hessian_dist']*1.25, n_y_samples)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    samples = (abscissa * X.reshape((-1, 1)) + ordinate * Y.reshape((-1, 1))).reshape((-1,) + origin.shape[1:])\n",
    "    samples = origin + torchify(samples)\n",
    "    exact_response = act_func(samples)\n",
    "    sr1_approx_response = curve_utils.hessian_approximate_response(act_grad_func, samples, sr1_hessian)\n",
    "    autodiff_approx_response = curve_utils.hessian_approximate_response(act_grad_func, samples, autodiff_hessian)\n",
    "    sr1_total_error = (exact_response - sr1_approx_response)\n",
    "    autodiff_total_error = (exact_response - autodiff_approx_response)\n",
    "    sr1_rms_error = np.sqrt(np.mean(np.square(sr1_total_error.detach().cpu().numpy())))\n",
    "    autodiff_rms_error = np.sqrt(np.mean(np.square(autodiff_total_error.detach().cpu().numpy())))\n",
    "    return sr1_rms_error, autodiff_rms_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_hessian_tests > 0:\n",
    "    sr1_errors = []\n",
    "    autodiff_errors = []\n",
    "    valid_indices = [i for i in range(data_natural['images'].shape[0]) if np.isfinite(data_natural['pert_lengths'][i, 2])]\n",
    "    image_indices = np.random.choice(valid_indices, size=num_hessian_tests, replace=False)\n",
    "    for image_idx in image_indices:\n",
    "        adv_idx = 0\n",
    "        boundary_image, boundary_dir, pert_length = get_paired_boundary_image(\n",
    "            model=model_natural,\n",
    "            origin=data_natural['images'][image_idx, ...],\n",
    "            alt_image=data_natural['advs'][image_idx, adv_idx, ...],\n",
    "            num_steps_per_iter=num_steps_per_iter,\n",
    "            num_iters=num_iters\n",
    "        )\n",
    "\n",
    "        sr1_rms_error, autodiff_rms_error = get_hessian_error(\n",
    "            model=model_natural,\n",
    "            origin=torchify(boundary_image[None,...]),\n",
    "            clean_lbl=int(data_natural['labels'][image_idx]),\n",
    "            adv_lbl=int(data_natural['adv_class'][image_idx, adv_idx]),\n",
    "            abscissa=boundary_dir,\n",
    "            ordinate=data_natural['advs'][image_idx, adv_idx+1],\n",
    "            hess_params=hess_params\n",
    "        )\n",
    "        sr1_errors.append(sr1_rms_error)\n",
    "        autodiff_errors.append(autodiff_rms_error)\n",
    "\n",
    "    print(f'Average RMS error over {num_hessian_tests} images with an l2 radius of {hess_params[\"hessian_dist\"]:.3f} for\\nSR1 Hessian:\\t\\t{np.mean(sr1_errors):.3f}\\nAutodiff hessian:\\t{np.mean(autodiff_errors):.3f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if autodiff:\n",
    "    filename = '../data/cifar_curvatures_and_directions_autodiff.npz'\n",
    "else:\n",
    "    filename = '../data/cifar_curvatures_and_directions_sr1.npz'\n",
    "\n",
    "if load:\n",
    "    data = np.load(filename, allow_pickle=True)['data'].item()\n",
    "    data_paired_natural = data['data_paired_natural']\n",
    "    data_paired_madry = data['data_paired_madry']\n",
    "    paired_shape_operators = data['paired_shape_operators']\n",
    "    paired_principal_curvatures = data['paired_principal_curvatures']\n",
    "    paired_principal_directions = data['paired_principal_directions']\n",
    "    paired_mean_curvatures = data['paired_mean_curvatures']\n",
    "    paired_origin_indices = data['paired_origin_indices']\n",
    "    adv_shape_operators = data['adv_shape_operators']\n",
    "    adv_principal_curvatures = data['adv_principal_curvatures']\n",
    "    adv_principal_directions = data['adv_principal_directions']\n",
    "    adv_mean_curvatures = data['adv_mean_curvatures']\n",
    "    adv_origin_indices = data['adv_origin_indices']\n",
    "    del data\n",
    "else:\n",
    "    #data_paired_natural = generate_paired_dict(data_natural, model_natural, num_images, num_advs)\n",
    "    #data_paired_madry = generate_paired_dict(data_madry, model_madry, num_images, num_advs)\n",
    "    paired_condition_zip = zip([model_natural, model_madry], [data_paired_natural, data_paired_madry])\n",
    "    paired_shape_operators, paired_principal_curvatures, paired_principal_directions, paired_origin_indices = get_curvature(\n",
    "        paired_condition_zip, num_images, num_advs, num_eps, batch_size, buffer_portion, autodiff)\n",
    "    paired_mean_curvatures = np.mean(paired_principal_curvatures, axis=-1)\n",
    "    adv_condition_zip = zip([model_natural, model_madry], [data_natural, data_madry])\n",
    "    adv_shape_operators, adv_principal_curvatures, adv_principal_directions, adv_origin_indices = get_curvature(\n",
    "        adv_condition_zip, num_images, num_advs, num_eps, batch_size, buffer_portion, autodiff)\n",
    "    adv_mean_curvatures = np.mean(adv_principal_curvatures, axis=-1)\n",
    "    save_dict = {\n",
    "        'data_paired_natural':data_paired_natural,\n",
    "        'data_paired_madry':data_paired_madry,\n",
    "        'paired_shape_operators': paired_shape_operators,\n",
    "        'paired_principal_curvatures': paired_principal_curvatures,\n",
    "        'paired_principal_directions': paired_principal_directions,\n",
    "        'paired_mean_curvatures': paired_mean_curvatures,\n",
    "        'paired_origin_indices': paired_origin_indices,\n",
    "        'adv_shape_operators': adv_shape_operators,\n",
    "        'adv_principal_curvatures': adv_principal_curvatures,\n",
    "        'adv_principal_directions': adv_principal_directions,\n",
    "        'adv_mean_curvatures': adv_mean_curvatures,\n",
    "        'adv_origin_indices': adv_origin_indices\n",
    "    }\n",
    "    np.savez(filename, data=save_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_and_data(data_nat, data_mad):\n",
    "    diff_str = '_diff' if autodiff else '_nodiff'\n",
    "    for model, data, name in zip([model_natural, model_madry], [data_nat, data_mad], ['natural'+diff_str, 'madry'+diff_str]):\n",
    "        image_shape = data['images'][0,...].shape\n",
    "        clean_count = 0\n",
    "        adv_count = 0\n",
    "        clean_imgs = torchify(data['images'])\n",
    "        clean_model_predictions = torch.argmax(model(clean_imgs), dim=1).detach().cpu().numpy()\n",
    "        for img_idx in range(data['images'].shape[0]):\n",
    "            label = int(data['labels'][img_idx])\n",
    "            prediction = int(clean_model_predictions[img_idx])\n",
    "            #assert  prediction == label , f'{name}: img_idx={img_idx}; prediction={prediction}; label={label}'\n",
    "            #if clean_model_predictions[img_idx] != data['labels'][img_idx]: print(f'{name}: img_idx={img_idx}; prediction={clean_model_predictions[img_idx]}; label={data[\"labels\"][img_idx]}')\n",
    "            if clean_model_predictions[img_idx] != data['labels'][img_idx]: clean_count += 1\n",
    "            adv_imgs = torchify(data['advs'][img_idx, ...].reshape((-1,)+image_shape))\n",
    "            adv_model_predictions = torch.argmax(model(adv_imgs), dim=1).detach().cpu().numpy()\n",
    "            for adv_idx in range(data['adv_class'].shape[1]):\n",
    "                if np.isfinite(data['pert_lengths'][img_idx, adv_idx]):\n",
    "                    label = int(data['adv_class'][img_idx, adv_idx])\n",
    "                    prediction = int(adv_model_predictions[adv_idx])\n",
    "                    #assert  prediction == label, f'{name}: img_idx={img_idx}, adv_idx={adv_idx}, prediction={prediction}, adv_label={label}'\n",
    "                    #if adv_model_predictions[adv_idx] != data['adv_class'][img_idx, adv_idx]: print(f'{name}: img_idx={img_idx}, adv_idx={adv_idx}, prediction={adv_model_predictions[adv_idx]}, label={data[\"adv_class\"][img_idx, adv_idx]}')\n",
    "                    if adv_model_predictions[adv_idx] != data['adv_class'][img_idx, adv_idx]: adv_count += 1\n",
    "        print(f'{name}: number of clean images with bad predictions = {clean_count}; number of adv images with bad predictions = {adv_count}')\n",
    "\n",
    "test_model_and_data(data_paired_natural, data_paired_madry)\n",
    "test_model_and_data(data_natural, data_madry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_width = 0.5\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, sharey=True, figsize=(12,7))\n",
    "fig.subplots_adjust(top=0.8)\n",
    "\n",
    "for data_idx, mean_curvatures in enumerate([paired_mean_curvatures, adv_mean_curvatures]):\n",
    "    for model_idx in range(2):\n",
    "        boxprops = dict(color=plot_colors[model_idx], linewidth=1.5, alpha=0.7)\n",
    "        whiskerprops = dict(color=plot_colors[model_idx], alpha=0.7)\n",
    "        capprops = dict(color=plot_colors[model_idx], alpha=0.7)\n",
    "        medianprops = dict(linestyle='--', linewidth=0.5, color=plot_colors[model_idx])\n",
    "        meanpointprops = dict(marker='o', markeredgecolor='black',\n",
    "                              markerfacecolor=plot_colors[model_idx])\n",
    "        meanprops = dict(linestyle='-', linewidth=0.5, color=plot_colors[model_idx])\n",
    "        data = mean_curvatures[model_idx, :, :].reshape(-1)\n",
    "        axs[data_idx].boxplot(data, sym='', positions=[model_idx], whis=(10, 90), widths=bar_width, meanline=True, showmeans=True, boxprops=boxprops,\n",
    "            whiskerprops=whiskerprops, capprops=capprops, medianprops=medianprops, meanprops=meanprops)\n",
    "    axs[data_idx].set_xticks([0, 1], minor=False)\n",
    "    axs[data_idx].set_xticks([], minor=True)\n",
    "    axs[data_idx].set_xticklabels(model_types)\n",
    "    if data_idx == 0:\n",
    "        axs[data_idx].set_ylabel('Mean curvature')\n",
    "        axs[data_idx].set_title('Paired image boundary')\n",
    "    else:\n",
    "        axs[data_idx].set_title('Adversarial image boundary')\n",
    "\n",
    "for model_idx in range(adv_mean_curvatures.shape[0]):\n",
    "    boxprops = dict(color=plot_colors[model_idx], linewidth=1.5, alpha=0.7)\n",
    "    whiskerprops = dict(color=plot_colors[model_idx], alpha=0.7)\n",
    "    capprops = dict(color=plot_colors[model_idx], alpha=0.7)\n",
    "    medianprops = dict(linestyle='--', linewidth=0.5, color=plot_colors[model_idx])\n",
    "    meanpointprops = dict(marker='o', markeredgecolor='black',\n",
    "                          markerfacecolor=plot_colors[model_idx])\n",
    "    meanprops = dict(linestyle='-', linewidth=0.5, color=plot_colors[model_idx])\n",
    "    for adv_idx in range(adv_mean_curvatures.shape[-1]):\n",
    "        data = adv_mean_curvatures[model_idx, :, adv_idx].reshape(-1)\n",
    "        axs[2].boxplot(data, sym='', positions=[adv_idx], whis=(10, 90), widths=bar_width, meanline=True, showmeans=True, boxprops=boxprops,\n",
    "            whiskerprops=whiskerprops, capprops=capprops, medianprops=medianprops, meanprops=meanprops)\n",
    "axs[2].set_title('Adversarial image boundary')\n",
    "axs[2].set_xlabel('Dimension number')\n",
    "axs[2].set_xticks([i for i in range(adv_mean_curvatures.shape[-1])], minor=False)\n",
    "axs[2].set_xticks([], minor=True)\n",
    "axs[2].set_xticklabels([str(i+1) for i in range(adv_mean_curvatures.shape[-1])])\n",
    "\n",
    "def make_space_above(axes, topmargin=1):\n",
    "    \"\"\" increase figure size to make topmargin (in inches) space for \n",
    "        titles, without changing the axes sizes\n",
    "        obtained from: https://stackoverflow.com/a/55768955/\n",
    "    \"\"\"\n",
    "    fig = axes.flatten()[0].figure\n",
    "    s = fig.subplotpars\n",
    "    w, h = fig.get_size_inches()\n",
    "\n",
    "    figh = h - (1 - s.top) * h + topmargin\n",
    "    fig.subplots_adjust(bottom=s.bottom*h/figh, top=1-topmargin/figh)\n",
    "    fig.set_figheight(figh)\n",
    "\n",
    "make_space_above(axs, topmargin=0.5)  \n",
    "\n",
    "fig.suptitle(f'Curvature at the decision boundary\\nfor {num_images} images and the first {num_advs} adversarial directions', y=1.0)\n",
    "plt.show()\n",
    "#fig.savefig('../data/cifar_mean_curvature_boxplots.pdf', transparent=True, bbox_inches='tight', pad_inches=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_width = 0.5\n",
    "fig, axs = pplt.subplots(nrows=1, ncols=2, sharey=True, figwidth=figwidth)\n",
    "titles = ['Test image boundary', 'Adversarial image boundary']\n",
    "for data_idx, mean_curvatures in enumerate([paired_mean_curvatures, adv_mean_curvatures]):\n",
    "    data = pd.DataFrame(mean_curvatures.reshape(-1, np.prod(mean_curvatures.shape[1:])).transpose(1, 0),\n",
    "                        columns=pd.Index(model_types, name=''))\n",
    "    axs[data_idx].boxplot(data, fill=True, mean=True,\n",
    "                          cycle=pplt.Cycle(plot_colors),\n",
    "                          linewidth=0.5,\n",
    "                          meanlinestyle='-', medianlinestyle='--',\n",
    "                          marker='o', markersize=1.0\n",
    "                         )\n",
    "    axs[data_idx].format(\n",
    "        xticklabels=model_types,\n",
    "        ylabel='Mean curvature',\n",
    "        title=titles[data_idx],\n",
    "        xgrid=False\n",
    "    )\n",
    "    axs[data_idx].axhline(0.0, color='black', linestyle='dashed', linewidth=0.5)\n",
    "\n",
    "\n",
    "#axs.format(\n",
    "#    suptitle=f'Curvature at the decision boundary',#\\naveraged across {num_images} images and the first {num_advs} adversarial directions'\n",
    "#)\n",
    "\n",
    "pplt.show()\n",
    "fig.savefig('../data/cifar_mean_curvature_boxplots.pdf', transparent=True, bbox_inches='tight', pad_inches=0.01, dpi=dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_models, num_images, num_advs, num_dims = adv_principal_curvatures.shape\n",
    "\n",
    "fig, ax = pplt.subplots(nrows=1, ncols=1, figwidth=figwidth_inch/2, dpi=dpi, sharey=False, sharex=False)\n",
    "for image_idx in range(num_images):\n",
    "    for adv_idx in range(num_advs):\n",
    "        ax.scatter(adv_principal_curvatures[0, image_idx, adv_idx, :],\n",
    "                   s=0.01, c=plot_colors[0])\n",
    "        ax.scatter(adv_principal_curvatures[1, image_idx, adv_idx, :],\n",
    "                   s=0.01, c=plot_colors[1])\n",
    "        \n",
    "ix = ax.inset(\n",
    "    bounds=[200, 0.50, 400, 1.5],\n",
    "    transform='data', zoom=True,\n",
    "    zoom_kw={'edgecolor': 'k', 'lw': 1, 'ls': '--'}\n",
    ")\n",
    "ix.format(\n",
    "    xlim=(0, num_dims), ylim=(-0.02, 0.02), metacolor='red7',\n",
    "    grid=False,\n",
    "    linewidth=1.5, ticklabelweight='bold'\n",
    ")\n",
    "ix.plot([0, num_dims], [0, 0], lw=0.1, c='k')\n",
    "ix.scatter(adv_principal_curvatures[0, ...].mean(axis=(0, 1)),\n",
    "           s=0.005, alpha=1.0, c=plot_colors[0])\n",
    "ix.scatter(adv_principal_curvatures[1, ...].mean(axis=(0, 1)),\n",
    "           s=0.005, alpha=1.0, c=plot_colors[1])\n",
    "\n",
    "ax.format(\n",
    "    title=f'Curvature profile, averaged across {num_images} images',\n",
    "    xlim=(-5, num_dims+5),\n",
    "    ylabel='Curvature',\n",
    "    xlabel='Principal curvature direction',\n",
    "    grid=False\n",
    ")\n",
    "for ax_loc in ['top', 'right']:\n",
    "    ax.spines[ax_loc].set_color('none')\n",
    "pplt.show()\n",
    "\n",
    "fig.savefig('../data/cifar_curvature_profile.pdf', transparent=True, bbox_inches='tight', pad_inches=0.01, dpi=dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# y & x axis should be the same scale\n",
    "# no need to have a dot on the y axis, should use an arrow instead\n",
    "num_plot_images = 3\n",
    "offset = 0\n",
    "\n",
    "for model_idx, (model_, data_) in enumerate(zip([model_natural, ], [data_natural, ])):\n",
    "    num_models, num_images, num_advs, num_directions, num_pixels = adv_principal_directions.shape\n",
    "    \n",
    "    fig, axs = pplt.subplots(nrows=3, ncols=num_plot_images, figwidth=figwidth, dpi=dpi, hspace=2, wspace=2)\n",
    "    axs.format(\n",
    "        ylabel = 'Principal curvature direction'\n",
    "    )\n",
    "    for image_idx in range(offset, offset+num_plot_images):\n",
    "        adv_idx = np.random.randint(low=0, high=num_advs)\n",
    "        most_flat_index = np.argmin(np.abs(adv_principal_curvatures[model_idx, image_idx, adv_idx, :]))\n",
    "        curvature_indices = [0, most_flat_index, -1]\n",
    "        dataset_image_idx = adv_origin_indices[model_idx, image_idx]\n",
    "        origin = data_['images'][dataset_image_idx, ...]\n",
    "\n",
    "        boundary_image = get_paired_boundary_image(\n",
    "            model=model_,\n",
    "            origin=origin,\n",
    "            alt_image=data_['advs'][dataset_image_idx, adv_idx, ...],\n",
    "            num_steps_per_iter=num_steps_per_iter,\n",
    "            num_iters=num_iters\n",
    "        )[0]\n",
    "        boundary_dist = np.linalg.norm(boundary_image.reshape(-1) - origin.reshape(-1))\n",
    "\n",
    "        for ax_idx, curvature_idx in enumerate(curvature_indices):\n",
    "            ax = axs[ax_idx, image_idx-offset]\n",
    "            adv1 = boundary_image.reshape(-1)\n",
    "            principal_direction = adv_principal_directions[model_idx, image_idx, adv_idx, :, curvature_idx]\n",
    "            # Source of error?\n",
    "            adv2 = origin.reshape(-1) + boundary_dist * principal_direction\n",
    "            dec_advs, labels = pl.plot_dec_space(origin[None, ...], adv1, adv2, model_, offset=1.0,\n",
    "                              n_grid=100, len_grid_scale=1.8, show_legend=False, show_advs=True,\n",
    "                              overlay_inbounds=True, ax=ax)\n",
    "            ax.legend(handles=labels, loc='upper left', ncols=1, title='predicted\\nclass')\n",
    "            ax.format(\n",
    "                title=f'Curvature = {adv_principal_curvatures[model_idx, image_idx, adv_idx, curvature_idx]:.5f}',\n",
    "                xlabel=f'Adversarial direction number {adv_idx}',\n",
    "            )\n",
    "    plt.show()\n",
    "    fig.savefig(f'../data/cifar_curvature_visualizations.pdf', transparent=True, bbox_inches='tight', pad_inches=0.01, dpi=dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../data/cifar_subspace_curvatures_autodiff.npz'\n",
    "\n",
    "if load:\n",
    "    data = np.load(filename, allow_pickle=True)['data'].item()\n",
    "    rand_pcs = data['random_principal_curvatures']\n",
    "    adv_pcs = data['adversarial_principal_curvatures']\n",
    "\n",
    "else:\n",
    "    dtype = torch.double\n",
    "    subspace_size = num_advs-1\n",
    "\n",
    "    rand_pcs = np.zeros((num_models, num_images, subspace_size))\n",
    "    adv_pcs = np.zeros((num_models, num_images, subspace_size))\n",
    "    for model_idx, (model_, data_) in enumerate(zip((model_natural, model_madry), (data_natural, data_madry))):\n",
    "        pbar = tqdm(total=num_images, leave=False)\n",
    "        for image_idx, origin_idx in enumerate(adv_origin_indices[model_idx, :]):\n",
    "            for adv_idx in range(num_advs):\n",
    "                boundary_image, boundary_dir, pert_length = get_paired_boundary_image(\n",
    "                        model=model_,\n",
    "                        origin=data_['images'][origin_idx, ...],\n",
    "                        alt_image=data_['advs'][origin_idx, adv_idx, ...],\n",
    "                        num_steps_per_iter=num_steps_per_iter,\n",
    "                        num_iters=num_iters)\n",
    "\n",
    "                clean_lbl = int(data_['labels'][origin_idx])\n",
    "                adv_lbl = int(data_['adv_class'][origin_idx, adv_idx])\n",
    "\n",
    "                activation, gradient = paired_activation_and_gradient(model_, torchify(boundary_image[None, ...]), clean_lbl, adv_lbl)\n",
    "                gradient = gradient.reshape(-1).type(dtype)\n",
    "                def func(x):\n",
    "                    acts_diff = paired_activation(model_, x, clean_lbl, adv_lbl)\n",
    "                    return acts_diff\n",
    "                hessian = torch.autograd.functional.hessian(func, torchify(boundary_image[None,...]))\n",
    "                hessian = hessian.reshape((int(boundary_image.size), int(boundary_image.size))).type(dtype)\n",
    "\n",
    "                dirs = [(gradient / torch.linalg.norm(gradient)).detach().cpu().numpy()]\n",
    "                n_pixels = gradient.numel()\n",
    "                n_iterations = 3\n",
    "                random_basis = torch.from_numpy(make_orth_basis(dirs, n_pixels, n_iterations)[:subspace_size, :]).type(dtype)\n",
    "\n",
    "                curvature = curve_utils.local_response_curvature_isoresponse_surface(gradient, hessian, projection_subspace_of_interest=random_basis)\n",
    "                rand_subspace_curvatures = curvature[1].detach().cpu().numpy()\n",
    "\n",
    "                adv_dirs = data_['dirs'][origin_idx, :num_advs, ...].reshape(num_advs, n_pixels)\n",
    "                if adv_idx > 0 and adv_idx < num_advs: # exclude current perturbation direction\n",
    "                    adv_dirs = np.concatenate((adv_dirs[:adv_idx], adv_dirs[adv_idx+1:]))\n",
    "                elif adv_idx == 0:\n",
    "                    adv_dirs = adv_dirs[adv_idx+1:]\n",
    "                else:\n",
    "                    adv_dirs = adv_dirs[:adv_idx]\n",
    "\n",
    "                adv_basis = torch.from_numpy(adv_dirs).type(dtype)\n",
    "                curvature = curve_utils.local_response_curvature_isoresponse_surface(gradient, hessian, projection_subspace_of_interest=adv_basis)\n",
    "                adv_subspace_curvatures = curvature[1].detach().cpu().numpy()\n",
    "\n",
    "                rand_pcs[model_idx, image_idx, :] = rand_subspace_curvatures\n",
    "                adv_pcs[model_idx, image_idx, :] = adv_subspace_curvatures\n",
    "            pbar.update(1)\n",
    "        pbar.close()\n",
    "\n",
    "        save_dict = {\n",
    "            'random_principal_curvatures':rand_pcs,\n",
    "            'adversarial_principal_curvatures':adv_pcs,\n",
    "        }\n",
    "        np.savez(filename, data=save_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = pplt.subplots(nrows=1, ncols=2, figwidth=figwidth_inch, dpi=dpi)\n",
    "\n",
    "percentiles = np.percentile(rand_pcs[0, ...], (5, 95), axis=0)\n",
    "std = np.std(rand_pcs[0, ...], axis=0)\n",
    "\n",
    "axs[0].scatter(rand_pcs[0, ...].mean(axis=0), s=2.0, c=plot_colors[0],\n",
    "               bardata=np.std(rand_pcs[0, ...], axis=0), barc=plot_colors[0], barlw=0.5, capsize=0.0,)\n",
    "axs[0].scatter(rand_pcs[1, ...].mean(axis=0), s=2.0, c=plot_colors[1],\n",
    "               bardata=np.std(rand_pcs[1, ...], axis=0), barc=plot_colors[1], barlw=0.5, capsize=0.0,)\n",
    "axs[0].axhline(0.0, color='black', linestyle='dashed', linewidth=0.5)\n",
    "axs[0].format(\n",
    "    title=f'Random subspaces'\n",
    ")\n",
    "for ax_loc in ['top', 'right']:\n",
    "    axs[0].spines[ax_loc].set_color('none')\n",
    "\n",
    "axs[1].scatter(adv_pcs[0, ...].mean(axis=0), s=2.0, c=plot_colors[0],\n",
    "               bardata=np.std(adv_pcs[0, ...], axis=0), barc=plot_colors[0], barlw=0.5, capsize=0.0,)\n",
    "axs[1].scatter(adv_pcs[1, ...].mean(axis=0), s=2.0, c=plot_colors[1],\n",
    "               bardata=np.std(adv_pcs[1, ...], axis=0), barc=plot_colors[1], barlw=0.5, capsize=0.0,)\n",
    "axs[1].axhline(0.0, color='black', linestyle='dashed', linewidth=0.5)\n",
    "axs[1].format(\n",
    "    title=f'Adversarial subspaces'\n",
    ")\n",
    "for ax_loc in ['top', 'right']:\n",
    "    axs[1].spines[ax_loc].set_color('none')\n",
    "\n",
    "axs.format(\n",
    "    ylabel='Curvature',\n",
    "    xlabel='Principal curvature directions',\n",
    "    grid=False\n",
    ")\n",
    "\n",
    "legend_handles = [mpatches.Patch(color=plot_colors[0], label='Natural'),\n",
    "                  mpatches.Patch(color=plot_colors[1], label='Adversarial')]\n",
    "axs[0].legend(handles=legend_handles, loc='upper right', ncols=1, frame=False)\n",
    "\n",
    "pplt.show()\n",
    "\n",
    "fig.savefig(f'../data/cifar_subspace_curvatures.pdf', transparent=True, bbox_inches='tight', pad_inches=0.01, dpi=dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import svgutils.compose as sc\n",
    "from IPython.display import SVG, Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc.Figure(figwidth, figwidth, \n",
    "#    sc.Panel(sc.SVG('../data/mean_curvature_boxplots.svg')),\n",
    "#    sc.Panel(sc.SVG('../data/subspace_curvatures.svg')),\n",
    "#    sc.Panel(sc.SVG('../data/curvature_profile.svg'))\n",
    "#    ).save('compose.svg')\n",
    "#SVG('compose.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as etree\n",
    "import re\n",
    "from six import StringIO\n",
    "import requests\n",
    "\n",
    "import svgpathtools as svgpt\n",
    "from svgpath2mpl import parse_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagram = '../data/curvature_diagram.svg'\n",
    "imported_diagram = SVG(diagram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported_diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_paths, curve_attributes, svg_attributes = svgpt.svg2paths2(diagram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svg_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_attributes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_attributes[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_hex(c):\n",
    "    if c.startswith('#') and len(c) == 4:\n",
    "        return '#{0}{0}{1}{1}{2}{2}'.format(c[1], c[2], c[3])\n",
    "    return c\n",
    "\n",
    "paths = [parse_path(attrib['d']) for attrib in curve_attributes]\n",
    "facecolors = [normalize_hex(attrib.get('fill', 'none')) for attrib in curve_attributes]\n",
    "edgecolors = [normalize_hex(attrib.get('stroke', 'none')) for attrib in curve_attributes]\n",
    "linewidths = [attrib.get('stroke_width', 1) for attrib in curve_attributes]\n",
    "collection = mpl.collections.PathCollection(paths, \n",
    "                                      edgecolors=edgecolors, \n",
    "                                      linewidths=linewidths,\n",
    "                                      facecolors=facecolors)\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111)\n",
    "collection.set_transform(ax.transData)\n",
    "ax.add_artist(collection)\n",
    "#ax.set_xlim([0, 960])\n",
    "#ax.set_ylim([540, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [parse_path(attrib['d']) for attrib in curve_attributes]\n",
    "facecolors = [attrib.get('fill', 'none') for attrib in curve_attributes]\n",
    "edgecolors = [attrib.get('stroke', 'none') for attrib in curve_attributes]\n",
    "linewidths = [attrib.get('stroke_width', 1) for attrib in curve_attributes]\n",
    "collection = mpl.collections.PathCollection(paths, \n",
    "                                      edgecolors=edgecolors, \n",
    "                                      linewidths=linewidths,\n",
    "                                      facecolors=facecolors)\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111)\n",
    "collection.set_transform(ax.transData)\n",
    "ax.add_artist(collection)\n",
    "ax.set_xlim([0, 960])\n",
    "ax.set_ylim([540, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('http://thenewcode.com/assets/images/thumbnails/homer-simpson.svg')\n",
    "tree = etree.parse(StringIO(r.text))\n",
    "root = tree.getroot()\n",
    "width = int(re.match(r'\\d+', root.attrib['width']).group())\n",
    "height = int(re.match(r'\\d+', root.attrib['height']).group())\n",
    "path_elems = root.findall('.//{http://www.w3.org/2000/svg}path')\n",
    "paths = [parse_path(elem.attrib['d']) for elem in path_elems]\n",
    "facecolors = [elem.attrib.get('fill', 'none') for elem in path_elems]\n",
    "edgecolors = [elem.attrib.get('stroke', 'none') for elem in path_elems]\n",
    "linewidths = [elem.attrib.get('stroke_width', 1) for elem in path_elems]\n",
    "collection = mpl.collections.PathCollection(paths, \n",
    "                                      edgecolors=edgecolors, \n",
    "                                      linewidths=linewidths,\n",
    "                                      facecolors=facecolors)\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111)\n",
    "collection.set_transform(ax.transData)\n",
    "ax.add_artist(collection)\n",
    "ax.set_xlim([0, width])\n",
    "ax.set_ylim([height, 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
