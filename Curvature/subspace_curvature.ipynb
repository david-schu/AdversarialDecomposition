{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, './..')\n",
    "sys.path.insert(0, '../data')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import matplotlib.gridspec as gridspec\n",
    "import proplot as pplt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from models import model, eval\n",
    "import plots as pl\n",
    "from utils import dev, load_data, classification\n",
    "\n",
    "sys.path.insert(0, './../../')\n",
    "\n",
    "import response_contour_analysis.utils.model_handling as model_utils\n",
    "import response_contour_analysis.utils.dataset_generation as data_utils\n",
    "import response_contour_analysis.utils.histogram_analysis as hist_utils\n",
    "import response_contour_analysis.utils.principal_curvature as curve_utils\n",
    "import response_contour_analysis.utils.plotting as plot_utils\n",
    "\n",
    "# check device\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data & models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "# load data\n",
    "data_natural = np.load(f'../data/natural_{seed}.npy', allow_pickle=True).item()\n",
    "advs_nat = data_natural['advs']\n",
    "pert_lengths_nat = data_natural['pert_lengths']\n",
    "classes_nat = data_natural['adv_class']\n",
    "dirs_nat = data_natural['dirs']\n",
    "images_nat = data_natural['images']\n",
    "labels_nat = data_natural['labels']\n",
    "\n",
    "data_madry = np.load(f'../data/robust_{seed}.npy', allow_pickle=True).item()\n",
    "advs_madry = data_madry['advs']\n",
    "pert_lengths_madry = data_madry['pert_lengths']\n",
    "classes_madry = data_madry['adv_class']\n",
    "dirs_madry = data_madry['dirs']\n",
    "images_madry = data_madry['images']\n",
    "labels_madry = data_madry['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "madry(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (maxPool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (maxPool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=3136, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load models\n",
    "model_natural = model.madry()\n",
    "model_natural.load_state_dict(torch.load(f'./../models/natural_{seed}.pt', map_location=DEVICE))\n",
    "model_natural.to(DEVICE)\n",
    "\n",
    "model_madry = model.madry()\n",
    "model_madry.load_state_dict(torch.load(f'./../models/robust_{seed}.pt', map_location=DEVICE))\n",
    "model_madry.to(DEVICE)\n",
    "\n",
    "model_random = model.madry()\n",
    "model_random.load_state_dict(torch.load('./../models/random.pt', map_location=DEVICE))\n",
    "model_random.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plane curvature for one pair of dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment_params = dict()\n",
    "\n",
    "#experiment_params['target_model_id'] = 0\n",
    "#experiment_params['data_shape'] = images_nat[0,...].shape\n",
    "#experiment_params['window_scale'] = 2.0\n",
    "#experiment_params['num_edge_images'] = 30\n",
    "#experiment_params['target'] = 0.0\n",
    "#experiment_params['target_is_act'] = True\n",
    "\n",
    "#experiment_params['num_images'] = int(experiment_params['num_edge_images']**2)\n",
    "#experiment_params['x_range'] = (-experiment_params['window_scale'], experiment_params['window_scale'])\n",
    "#experiment_params['y_range'] = experiment_params['x_range']\n",
    "#experiment_params['device'] = DEVICE\n",
    "#yx_range = experiment_params['yx_range'] = (experiment_params['y_range'], experiment_params['x_range'])\n",
    "\n",
    "hess_params = dict()\n",
    "hess_params['hessian_num_pts'] = 1e4\n",
    "hess_params['hessian_lr'] = 1e-3\n",
    "hess_params['hessian_random_walk'] = False\n",
    "hess_params['return_points'] = False\n",
    "buffer_portion = 0.25\n",
    "num_eps = 1000\n",
    "batch_size = 1000\n",
    "num_images = 100#labels_nat.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundary_image(model, origin, direction, length, origin_class, adv_class, num_eps, buffer_portion, batch_size):\n",
    "    linspace_min = buffer_portion * length\n",
    "    linspace_max = (1 + buffer_portion) * length\n",
    "    eps_vals = np.linspace(linspace_min, linspace_max, num_eps)\n",
    "    direction = direction.reshape(1, direction.size)\n",
    "    eps_vals = eps_vals.reshape(-1, 1)\n",
    "    origin = origin.reshape(1, origin.size)\n",
    "    adv_line = origin + (direction * eps_vals)\n",
    "    adv_line = adv_line.reshape(-1, 1, int(np.sqrt(img.size)), int(np.sqrt(img.size)))\n",
    "    num_batches = int(np.ceil(num_eps / batch_size))\n",
    "    input_batches = torch.split(torch.from_numpy(adv_line).to(DEVICE).float(), num_batches)\n",
    "    model_outputs = np.empty((0, 10))\n",
    "    for batch in input_batches:\n",
    "        batch_outputs = model(batch).detach().cpu().numpy()\n",
    "        model_outputs = np.concatenate((model_outputs, batch_outputs), axis=0)\n",
    "    decision_scores = model_outputs[:, int(origin_class)] - model_outputs[:, int(adv_class)]\n",
    "    boundary_index = np.abs(decision_scores).argmin()\n",
    "    boundary_image = adv_line[boundary_index]\n",
    "    return boundary_image\n",
    "\n",
    "\n",
    "def get_random_boundary_image(origins, directions, eps=0.01):\n",
    "    \"\"\"\n",
    "    TODO: Take several steps at once to use speedup advantage from batching\n",
    "    or batch over origins & directions to do many at once.\n",
    "    \"\"\"\n",
    "    num_images, num_channels, num_rows, num_cols = origins.shape\n",
    "    correct_labels = torch.argmax(model(origins))\n",
    "    pert_label = correct_labels\n",
    "    pert_image = origins.clone()\n",
    "    num_steps = 0\n",
    "    while torch.all(pert_label == correct_labels):\n",
    "        pert_image = pert_image + directions * eps\n",
    "        pert_label = torch.argmax(model(pert_image))\n",
    "        num_steps += 1\n",
    "    pert_image = origins + num_steps-1 * directions * eps\n",
    "    small_eps = eps * 0.01\n",
    "    num_small_steps = 0\n",
    "    while pert_label == correct_labels:\n",
    "        pert_image = pert_image + directions * small_eps\n",
    "        pert_label = torch.argmax(model(pert_image))\n",
    "        num_small_steps += 1\n",
    "    return pert_image\n",
    "    \n",
    "\n",
    "def random_vector(size):\n",
    "    components = [np.random.normal() for i in range(size)]\n",
    "    radius = np.sqrt(sum(x**2 for x in components))\n",
    "    vect = np.array([x/radius for x in components])\n",
    "    return vect\n",
    "\n",
    "def get_mean_curvatures(condition_zip, num_images, num_advs, num_eps, batch_size, buffer_portion, hess_radius_mult):\n",
    "    mean_curvatures = np.zeros((2, num_images, 2))\n",
    "    for model_idx, (model, data)  in enumerate(condition_zip):\n",
    "        advs = data['advs']\n",
    "        classes = data['adv_class']\n",
    "        dirs = data['dirs']\n",
    "        images = data['images']\n",
    "        labels = data['labels']\n",
    "        for image_idx in tqdm(range(num_images)):\n",
    "            clean_id = int(labels[image_idx])\n",
    "            adv_ids = classes[image_idx, ...]\n",
    "            img_dirs = dirs[image_idx,...]\n",
    "            img_advs = advs[image_idx,...]\n",
    "            img = images[image_idx,...].reshape(-1)\n",
    "            for adv_idx in range(2):\n",
    "                boundary_image = get_boundary_image(\n",
    "                    model=model,\n",
    "                    origin=img,\n",
    "                    direction=img_dirs[adv_idx],\n",
    "                    length=np.linalg.norm(img_advs[adv_idx, ...].reshape(-1) - img),\n",
    "                    origin_class=clean_id,\n",
    "                    adv_class=adv_ids[adv_idx],\n",
    "                    num_eps=num_eps,\n",
    "                    buffer_portion=buffer_portion,\n",
    "                    batch_size=batch_size) \n",
    "                hess_params['hessian_dist'] = np.linalg.norm(img_advs[adv_idx, ...].reshape(-1) - img) * hess_radius_mult # radius around the target image\n",
    "                torch_image = torch.from_numpy(boundary_image).to(DEVICE).float()[None, ...]\n",
    "                activation, gradient = model_utils.unit_activation_and_gradient(model, torch_image, clean_id)\n",
    "                gradient = gradient.reshape(-1)\n",
    "                def func(x):\n",
    "                    model.zero_grad()\n",
    "                    acts_diff = model(x)[:, clean_id] - model(x)[:, int(adv_ids[adv_idx])]\n",
    "                    grad = torch.autograd.grad(acts_diff, x)[0]\n",
    "                    return acts_diff, grad\n",
    "                #func = lambda x : model_utils.unit_activation_and_gradient(model, x, clean_id)\n",
    "                #hessian = torch.autograd.functional.hessian(func, torch_image, create_graph=True, strict=True)\n",
    "                #hessian = hessian.reshape((int(torch_image.numel()), int(torch_image.numel())))\n",
    "                hessian = curve_utils.sr1_hessian(\n",
    "                    func, torch_image,\n",
    "                    distance=hess_params['hessian_dist'],\n",
    "                    n_points=hess_params['hessian_num_pts'],\n",
    "                    random_walk=hess_params['hessian_random_walk'],\n",
    "                    learning_rate=hess_params['hessian_lr'],\n",
    "                    return_points=False,\n",
    "                    progress=False)\n",
    "                shape_operator, principal_curvatures, principal_directions = curve_utils.local_response_curvature(gradient, hessian)\n",
    "                mean_curvatures[model_idx, image_idx, adv_idx] = np.mean(principal_curvatures.detach().cpu().numpy())\n",
    "    return mean_curvatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 30, 1, 784)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advs_nat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 30, 1, 784)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dirs_nat.shape\n",
    "#data_natural = np.load(f'../data/natural_{seed}.npy', allow_pickle=True).item()\n",
    "#advs_nat = data_natural['advs']\n",
    "#pert_lengths_nat = data_natural['pert_lengths']\n",
    "#classes_nat = data_natural['adv_class']\n",
    "#dirs_nat = data_natural['dirs']\n",
    "#images_nat = data_natural['images']\n",
    "#labels_nat = data_natural['labels']\n",
    "\n",
    "num_images, num_advs, _, vector_length = data_natural['dirs'].shape\n",
    "data_rand = {}\n",
    "data_rand['images'] = data_natural['images'].copy()\n",
    "data_rand['labels'] = data_natural['labels'].copy()\n",
    "\n",
    "dirs = np.stack([random_vector(vector_length)[None, :] for _ in range(num_advs)], axis=0)\n",
    "dirs = np.repeat(dirs[None, ...], num_images, axis=0)\n",
    "data_rand['dirs'] = dirs\n",
    "\n",
    "advs = get_random_boundary_image(origin, direction, eps=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if random_dirs:\n",
    "else:\n",
    "    condition_zip = zip([model_natural, model_madry], [data_natural, data_madry])\n",
    "\n",
    "hess_radius_mult = 0.1\n",
    "num_advs = 2\n",
    "get_mean_curvatures(condition_zip, num_images, num_advs, num_eps, batch_size, buffer_portion, hess_radius_mult):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['blue', 'orange']\n",
    "bar_width = 0.5\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "for i in range(2):\n",
    "    boxprops = dict(color=colors[i], linewidth=1.5, alpha=0.7)\n",
    "    whiskerprops = dict(color=colors[i], alpha=0.7)\n",
    "    capprops = dict(color=colors[i], alpha=0.7)\n",
    "    medianprops = dict(linestyle='--', linewidth=0.5, color=colors[i])\n",
    "    meanpointprops = dict(marker='o', markeredgecolor='black',\n",
    "                          markerfacecolor=colors[i])\n",
    "    meanprops = dict(linestyle='-', linewidth=0.5, color=colors[i])\n",
    "    data = mean_curvatures[i, :, :].reshape(-1)\n",
    "    ax.boxplot(data, sym='', positions=[i], whis=(5, 95), widths=bar_width, meanline=True, showmeans=True, boxprops=boxprops,\n",
    "        whiskerprops=whiskerprops, capprops=capprops, medianprops=medianprops, meanprops=meanprops)\n",
    "ax.set_title(f'Curvature at the decision boundary for the first {mean_curvatures.shape[-1]} adversarial directions')\n",
    "ax.set_ylabel('Mean curvature')\n",
    "ax.set_xticks([0, 1], minor=False)\n",
    "ax.set_xticks([], minor=True)\n",
    "ax.set_xticklabels(['Naturally trained', 'Adversarially trained'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
