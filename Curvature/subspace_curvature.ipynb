{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, './..')\n",
    "sys.path.insert(0, '../data')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import matplotlib.gridspec as gridspec\n",
    "import proplot as pplt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from models import model, eval\n",
    "import plots as pl\n",
    "from utils import dev, load_data, classification\n",
    "\n",
    "sys.path.insert(0, './../../')\n",
    "\n",
    "import response_contour_analysis.utils.model_handling as model_utils\n",
    "import response_contour_analysis.utils.dataset_generation as data_utils\n",
    "import response_contour_analysis.utils.histogram_analysis as hist_utils\n",
    "import response_contour_analysis.utils.principal_curvature as curve_utils\n",
    "import response_contour_analysis.utils.plotting as plot_utils\n",
    "\n",
    "# check device\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment_params = dict()\n",
    "\n",
    "#experiment_params['target_model_id'] = 0\n",
    "#experiment_params['data_shape'] = images_nat[0,...].shape\n",
    "#experiment_params['window_scale'] = 2.0\n",
    "#experiment_params['num_edge_images'] = 30\n",
    "#experiment_params['target'] = 0.0\n",
    "#experiment_params['target_is_act'] = True\n",
    "\n",
    "#experiment_params['num_images'] = int(experiment_params['num_edge_images']**2)\n",
    "#experiment_params['x_range'] = (-experiment_params['window_scale'], experiment_params['window_scale'])\n",
    "#experiment_params['y_range'] = experiment_params['x_range']\n",
    "#experiment_params['device'] = DEVICE\n",
    "#yx_range = experiment_params['yx_range'] = (experiment_params['y_range'], experiment_params['x_range'])\n",
    "\n",
    "hess_params = dict()\n",
    "hess_params['hessian_num_pts'] = 1e4\n",
    "hess_params['hessian_lr'] = 1e-3\n",
    "hess_params['hessian_random_walk'] = False\n",
    "hess_params['return_points'] = False\n",
    "num_iters = 2 # for paired image boundary search\n",
    "num_steps_per_iter = 10#100 # for paired image boundary search\n",
    "buffer_portion = 0.25\n",
    "num_eps = 1000\n",
    "batch_size = 1000\n",
    "num_images = 50#labels_nat.size\n",
    "hess_radius_mult = 0.1\n",
    "num_advs = 8\n",
    "autodiff = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data & models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "# load data\n",
    "data_natural = np.load(f'../data/natural_{seed}.npy', allow_pickle=True).item()\n",
    "advs_nat = data_natural['advs']\n",
    "pert_lengths_nat = data_natural['pert_lengths']\n",
    "classes_nat = data_natural['adv_class']\n",
    "dirs_nat = data_natural['dirs']\n",
    "images_nat = data_natural['images']\n",
    "labels_nat = data_natural['labels']\n",
    "\n",
    "data_madry = np.load(f'../data/robust_{seed}.npy', allow_pickle=True).item()\n",
    "advs_madry = data_madry['advs']\n",
    "pert_lengths_madry = data_madry['pert_lengths']\n",
    "classes_madry = data_madry['adv_class']\n",
    "dirs_madry = data_madry['dirs']\n",
    "images_madry = data_madry['images']\n",
    "labels_madry = data_madry['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "if autodiff:\n",
    "    model_natural = model.madry_diff()\n",
    "    model_madry = model.madry_diff()\n",
    "    model_random = model.madry_diff()\n",
    "else:\n",
    "    model_natural = model.madry()\n",
    "    model_madry = model.madry()\n",
    "    model_random = model.madry()\n",
    "\n",
    "model_natural.load_state_dict(torch.load(f'./../models/natural_{seed}.pt', map_location=DEVICE))\n",
    "model_natural.to(DEVICE)\n",
    "\n",
    "model_madry.load_state_dict(torch.load(f'./../models/robust_{seed}.pt', map_location=DEVICE))\n",
    "model_madry.to(DEVICE)\n",
    "\n",
    "model_random.load_state_dict(torch.load('./../models/random.pt', map_location=DEVICE))\n",
    "model_random.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plane curvature for one pair of dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torchify(img):\n",
    "    if autodiff:\n",
    "        output = torch.from_numpy(img).type(torch.DoubleTensor).to(DEVICE)\n",
    "    else:\n",
    "        output = torch.from_numpy(img).type(torch.FloatTensor).to(DEVICE)\n",
    "    return output\n",
    "\n",
    "\n",
    "def get_adv_boundary_image(model, origin, direction, length, origin_class, adv_class, num_eps, buffer_portion, batch_size, autodiff):\n",
    "    linspace_min = buffer_portion * length\n",
    "    linspace_max = (1 + buffer_portion) * length\n",
    "    eps_vals = np.linspace(linspace_min, linspace_max, num_eps)\n",
    "    direction = direction.reshape(1, direction.size)\n",
    "    eps_vals = eps_vals.reshape(-1, 1)\n",
    "    origin = origin.reshape(1, origin.size)\n",
    "    adv_line = origin + (direction * eps_vals)\n",
    "    adv_line = adv_line.reshape(-1, 1, int(np.sqrt(origin.size)), int(np.sqrt(origin.size)))\n",
    "    num_batches = int(np.ceil(num_eps / batch_size))\n",
    "    if autodiff:\n",
    "        input_batches = torch.split(torch.from_numpy(adv_line).type(torch.DoubleTensor).to(DEVICE), num_batches)\n",
    "    else:\n",
    "        input_batches = torch.split(torch.from_numpy(adv_line).type(torch.FloatTensor).to(DEVICE), num_batches)\n",
    "    model_outputs = np.empty((0, 10))\n",
    "    for batch in input_batches:\n",
    "        batch_outputs = model(batch).detach().cpu().numpy()\n",
    "        model_outputs = np.concatenate((model_outputs, batch_outputs), axis=0)\n",
    "    decision_scores = model_outputs[:, int(origin_class)] - model_outputs[:, int(adv_class)]\n",
    "    boundary_index = np.abs(decision_scores).argmin()\n",
    "    boundary_image = adv_line[boundary_index]\n",
    "    return boundary_image\n",
    "\n",
    "\n",
    "def get_paired_boundary_image(model, origin, alt_image, num_steps_per_iter, num_iters):\n",
    "    num_channels, num_rows, num_cols = origin.shape\n",
    "    input_shape = [1, num_channels, num_rows, num_cols]\n",
    "    def find_pert(img_line):\n",
    "        correct_lbl = torch.argmax(model(torchify(img_line[0, ...].reshape(input_shape))))\n",
    "        pert_lbl = correct_lbl.clone()\n",
    "        step_idx = 1 # already know the first one\n",
    "        while pert_lbl == correct_lbl:\n",
    "            pert_img = img_line[step_idx, ...]\n",
    "            pert_lbl = torch.argmax(model(torchify(img_line[step_idx, ...].reshape(input_shape))))\n",
    "            step_idx += 1\n",
    "        return step_idx-1, pert_img\n",
    "    img_line = np.linspace(origin.reshape(-1), alt_image.reshape(-1), num_steps_per_iter)\n",
    "    for search_iter in range(num_iters):\n",
    "        step_idx, pert_img = find_pert(img_line)\n",
    "        img_line = np.linspace(img_line[step_idx - 1, ...], img_line[step_idx, ...], num_steps_per_iter)\n",
    "    delta_image = origin - pert_image\n",
    "    pert_length = np.linalg.norm(delta_image)\n",
    "    direction = delta_image / pert_length\n",
    "    return pert_image.reshape(origin.shape), direction, pert_length\n",
    "\n",
    "\n",
    "def get_random_boundary_image(origin, eps=0.01, max_dist=4):\n",
    "    num_channels, num_rows, num_cols = origin.shape\n",
    "    direction = random_vector(num_channels * num_rows * num_cols)\n",
    "    correct_label = torch.argmax(model(origin))\n",
    "    pert_label = correct_label.clone()\n",
    "    pert_image = origin.clone()\n",
    "    num_steps = 0\n",
    "    while pert_label == correct_label:\n",
    "        pert_image = pert_image + direction * eps\n",
    "        pert_label = torch.argmax(model(pert_image))\n",
    "        num_steps += 1\n",
    "    pert_image = origin + num_steps-1 * direction * eps\n",
    "    small_eps = eps * 0.01\n",
    "    num_small_steps = 0\n",
    "    while pert_label == correct_label:\n",
    "        pert_image = pert_image + direction * small_eps\n",
    "        pert_label = torch.argmax(model(pert_image))\n",
    "        num_small_steps += 1\n",
    "    return pert_image\n",
    "    \n",
    "\n",
    "def random_vector(size):\n",
    "    components = [np.random.normal() for i in range(size)]\n",
    "    radius = np.sqrt(sum(x**2 for x in components))\n",
    "    vect = np.array([x/radius for x in components])\n",
    "    return vect\n",
    "\n",
    "\n",
    "def get_curvature(condition_zip, num_images, num_advs, num_eps, batch_size, buffer_portion, hess_radius_mult, autodiff=False):\n",
    "    models, adv_data = zip(*condition_zip)\n",
    "    num_models = len(models)\n",
    "    img_size = np.prod(adv_data[0]['images'][0,...].shape)\n",
    "    shape_operators = np.zeros((num_models, num_images, num_advs, img_size, img_size))\n",
    "    principal_curvatures = np.zeros((num_models, num_images, num_advs, img_size))\n",
    "    principal_directions = np.zeros((num_models, num_images, num_advs, img_size, img_size))\n",
    "    mean_curvatures = np.zeros((num_models, num_images, num_advs))\n",
    "    for model_idx, (model, data)  in enumerate(zip(models, adv_data)):\n",
    "        advs = data['advs']\n",
    "        classes = data['adv_class']\n",
    "        dirs = data['dirs']\n",
    "        images = data['images']\n",
    "        labels = data['labels']\n",
    "        pbar = tqdm(total=num_images, leave=True)\n",
    "        image_idx = 0\n",
    "        processed_images = 0\n",
    "        while processed_images < num_images:\n",
    "            clean_id = int(labels[image_idx])\n",
    "            adv_ids = classes[image_idx, ...]\n",
    "            img_dirs = dirs[image_idx, ...]\n",
    "            img_advs = advs[image_idx, ...]\n",
    "            img = images[image_idx, ...]\n",
    "            if autodiff:\n",
    "                torch_image = torch.from_numpy(img).type(torch.DoubleTensor).to(DEVICE)[None, ...]\n",
    "            else:\n",
    "                torch_image = torch.from_numpy(img).type(torch.FloatTensor).to(DEVICE)[None, ...]\n",
    "            if torch.argmax(model(torch_image)) == clean_id: # model labeled the clean image correctly\n",
    "                img = img.reshape(-1)\n",
    "                for adv_idx in range(num_advs):\n",
    "                    boundary_image = get_adv_boundary_image(\n",
    "                        model=model,\n",
    "                        origin=img,\n",
    "                        direction=img_dirs[adv_idx],\n",
    "                        length=np.linalg.norm(img_advs[adv_idx, ...].reshape(-1) - img),\n",
    "                        origin_class=clean_id,\n",
    "                        adv_class=adv_ids[adv_idx],\n",
    "                        num_eps=num_eps,\n",
    "                        buffer_portion=buffer_portion,\n",
    "                        batch_size=batch_size,\n",
    "                        autodiff=autodiff) \n",
    "                    hess_params['hessian_dist'] = np.linalg.norm(img_advs[adv_idx, ...].reshape(-1) - img) * hess_radius_mult # radius around the target image\n",
    "                    if autodiff:\n",
    "                        torch_image = torch.from_numpy(boundary_image).type(torch.DoubleTensor).to(DEVICE)[None, ...]\n",
    "                    else:\n",
    "                        torch_image = torch.from_numpy(boundary_image).type(torch.FloatTensor).to(DEVICE)[None, ...]\n",
    "                    activation, gradient = model_utils.unit_activation_and_gradient(model, torch_image, clean_id)\n",
    "                    gradient = gradient.reshape(-1)\n",
    "                    if autodiff:\n",
    "                        def func(x):\n",
    "                            model.zero_grad()\n",
    "                            acts_diff = model(x)[:, clean_id] - model(x)[:, int(adv_ids[adv_idx])]\n",
    "                            return acts_diff\n",
    "                        hessian = torch.autograd.functional.hessian(func, torch_image).reshape(784,784)\n",
    "                        hessian = hessian.reshape((int(torch_image.numel()), int(torch_image.numel())))\n",
    "                    else:\n",
    "                        def func(x):\n",
    "                            model.zero_grad()\n",
    "                            acts_diff = model(x)[:, clean_id] - model(x)[:, int(adv_ids[adv_idx])]\n",
    "                            grad = torch.autograd.grad(acts_diff, x)[0]\n",
    "                            return acts_diff, grad\n",
    "                        hessian = curve_utils.sr1_hessian(\n",
    "                            func, torch_image,\n",
    "                            distance=hess_params['hessian_dist'],\n",
    "                            n_points=hess_params['hessian_num_pts'],\n",
    "                            random_walk=hess_params['hessian_random_walk'],\n",
    "                            learning_rate=hess_params['hessian_lr'],\n",
    "                            return_points=False,\n",
    "                            progress=False)\n",
    "                    curvature = curve_utils.local_response_curvature(gradient, hessian)\n",
    "                    shape_operators[model_idx, processed_images, adv_idx, ...] = curvature[0].detach().cpu().numpy()\n",
    "                    principal_curvatures[model_idx, processed_images, adv_idx, :] = curvature[1].detach().cpu().numpy()\n",
    "                    principal_directions[model_idx, processed_images, adv_idx, ...] = curvature[2].detach().cpu().numpy()\n",
    "                    mean_curvatures[model_idx, processed_images, adv_idx] = np.mean(curvature[1].detach().cpu().numpy())\n",
    "                pbar.update(1)\n",
    "                processed_images += 1\n",
    "            image_idx += 1\n",
    "        pbar.close()\n",
    "    return shape_operators, principal_curvatures, principal_directions, mean_curvatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = images_nat[0, ...]\n",
    "img_class1 = int(labels_nat[0])\n",
    "class_idx = 1\n",
    "img_class2 = int(labels_nat[class_idx])\n",
    "while img_class1 == img_class2:\n",
    "    class_idx += 1\n",
    "    img_class2 = int(labels_nat[class_idx])\n",
    "img2 = images_nat[class_idx, ...]\n",
    "img_line = np.linspace(img1.reshape(-1), img2.reshape(-1), num_steps_per_iter)\n",
    "\n",
    "num_channels, num_rows, num_cols = images_nat[0,...].shape\n",
    "input_shape = [1, num_channels, num_rows, num_cols]\n",
    "correct_label = torch.argmax(model_natural(torchify(img1.reshape(input_shape))))\n",
    "\n",
    "pert_label = correct_label.clone()\n",
    "step_idx = 0\n",
    "while pert_label == correct_label:\n",
    "    pert_image = img_line[step_idx, ...].reshape(input_shape)\n",
    "    pert_label = torch.argmax(model_natural(torchify(pert_image)))\n",
    "    step_idx += 1\n",
    "\n",
    "sm_img_line = np.linspace(img_line[step_idx - 2, ...], img_line[step_idx-1, ...], num_steps_per_iter)\n",
    "pert_label = torch.argmax(model_natural(torchify(sm_img_line[0]).reshape(input_shape)))\n",
    "small_step_idx = 1\n",
    "while pert_label == correct_label:\n",
    "    pert_image = sm_img_line[small_step_idx, ...].reshape(input_shape)\n",
    "    pert_label = torch.argmax(model_natural(torchify(pert_image)))\n",
    "    small_step_idx += 1\n",
    "\n",
    "fig, ax = plt.subplots(1, 6)\n",
    "ax[0].imshow(img_line[0, ...].reshape(images_nat[0,...].shape[-2:]), cmap='greys', vmin=0, vmax=1)\n",
    "ax[1].imshow(img_line[num_steps_per_iter//2, ...].reshape(images_nat[0,...].shape[-2:]), cmap='greys', vmin=0, vmax=1)\n",
    "ax[2].imshow(img_line[-1, ...].reshape(images_nat[0,...].shape[-2:]), cmap='greys', vmin=0, vmax=1)\n",
    "ax[3].imshow(pert_image.reshape(images_nat[0,...].shape[-2:]), cmap='greys', vmin=0, vmax=1)\n",
    "\n",
    "new_pert_image = get_paired_boundary_image(model_natural, img1, img2, num_steps_per_iter, num_iters)[0]\n",
    "ax[4].imshow(new_pert_image.reshape(images_nat[0,...].shape[-2:]), cmap='greys', vmin=0, vmax=1)\n",
    "ax[5].imshow(pert_image.reshape(images_nat[0,...].shape[-2:]) - new_pert_image.reshape(images_nat[0,...].shape[-2:]), cmap='greys', vmin=0, vmax=1)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(img_class1, img_class2, pert_label)\n",
    "print(img_line.shape)\n",
    "print(np.linalg.norm(pert_image.reshape(-1) - img1.reshape(-1)))\n",
    "print(np.allclose(pert_image.reshape(-1), new_pert_image.reshape(-1)))\n",
    "print(np.linalg.norm(pert_image.reshape(-1) - new_pert_image.reshape(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_paired_dict(data_dict, model, num_images):\n",
    "    output_dict = {}\n",
    "    output_dict['images'] = data_dict['images'].copy()\n",
    "    output_dict['labels'] = data_dict['labels'].copy()\n",
    "    origin = data_dict['images'][0, ...]\n",
    "    num_adv_directions = data_dict['adv_class'].shape[1]\n",
    "    shuffled_indices = np.random.choice([int(i) for i in range(data_dict['labels'].size)], size=data_dict['labels'].size, replace=False)\n",
    "    dirs = []\n",
    "    advs = []\n",
    "    pert_lengths = []\n",
    "    adv_class = []\n",
    "    img_idx = 0\n",
    "    processed_images = 0\n",
    "    while processed_images < num_images * num_adv_directions:\n",
    "        correct_class = int(data_dict['labels'][img_idx])\n",
    "        model_prediction = torch.argmax(model(torchify(origin[None, ...]))).item()\n",
    "        if correct_class == model_prediction:\n",
    "            adv_dir_idx = 0\n",
    "            search_index = 0\n",
    "            sub_adv_class = []\n",
    "            sub_advs = []\n",
    "            sub_dirs = []\n",
    "            sub_pert_lengths = []\n",
    "            while adv_dir_idx < num_adv_directions:\n",
    "                alt_index = shuffled_indices[search_index]\n",
    "                alt_class = int(labels_nat[alt_index])\n",
    "                alt_img = data_dict['images'][alt_index, ...][None,...]\n",
    "                model_prediction = torch.argmax(model(torchify(alt_img))).item()\n",
    "                search_index += 1\n",
    "                while (correct_class == alt_class) and (alt_class == model_prediction):\n",
    "                    alt_index = shuffled_indices[search_index]\n",
    "                    alt_class = int(labels_nat[alt_index])\n",
    "                    alt_img = data_dict['images'][alt_index, ...][None,...]\n",
    "                    model_prediction = torch.argmax(model(torchify(alt_img))).item()\n",
    "                    search_index += 1\n",
    "                alt_img = alt_img[0,...]\n",
    "                boundary_image, boundary_dir, pert_length = get_paired_boundary_image(model_natural, origin, alt_img, num_steps_per_iter, num_iters)\n",
    "                sub_adv_class.append(torch.argmax(model(torchify(boundary_image[None, ...]))).item())\n",
    "                sub_advs.append(boundary_image.reshape(1, -1))\n",
    "                sub_dirs.append(boundary_dir.reshape(1, -1))\n",
    "                sub_pert_lengths.append(pert_length)\n",
    "                adv_dir_idx += 1\n",
    "                processed_images += 1\n",
    "            adv_class.append(np.stack(sub_adv_class, axis=0))\n",
    "            advs.append(np.stack(sub_advs, axis=0))\n",
    "            dirs.append(np.stack(sub_dirs, axis=0))\n",
    "            pert_lengths.append(np.stack(sub_pert_lengths, axis=0))\n",
    "        img_idx += 1\n",
    "    output_dict['dirs'] = np.stack(dirs, axis=0)\n",
    "    output_dict['advs'] = np.stack(advs, axis=0)\n",
    "    output_dict['pert_lengths'] = np.stack(pert_lengths, axis=0)\n",
    "    output_dict['adv_class'] = np.stack(adv_class, axis=0)\n",
    "    return output_dict\n",
    "\n",
    "data_paired_natural = generate_paired_dict(data_natural, model_natural, num_images)\n",
    "data_paired_madry = generate_paired_dict(data_madry, model_madry, num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_condition_zip = zip([model_natural, model_madry], [data_paired_natural, data_paired_madry])\n",
    "adv_condition_zip = zip([model_natural, model_madry], [data_natural, data_madry])\n",
    "\n",
    "adv_shape_operators, adv_principal_curvatures, adv_principal_directions, adv_mean_curvatures = get_curvature(\n",
    "    adv_condition_zip, num_images, num_advs, num_eps, batch_size, buffer_portion, hess_radius_mult, autodiff)\n",
    "paired_shape_operators, paired_principal_curvatures, paired_principal_directions, paired_mean_curvatures = get_curvature(\n",
    "    paired_condition_zip, num_images, num_advs, num_eps, batch_size, buffer_portion, hess_radius_mult, autodiff)\n",
    "\n",
    "#np.savez('../../outputs/mean_curvatures_sr1.npz', data=mean_curvatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['blue', 'orange']\n",
    "bar_width = 0.5\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, sharey=True)\n",
    "for data_idx in range(2):\n",
    "    mean_curvatures = [paired_mean_curvatures, adv_mean_curvatures][data_idx]\n",
    "    for model_idx in range(2):\n",
    "        boxprops = dict(color=colors[model_idx], linewidth=1.5, alpha=0.7)\n",
    "        whiskerprops = dict(color=colors[model_idx], alpha=0.7)\n",
    "        capprops = dict(color=colors[model_idx], alpha=0.7)\n",
    "        medianprops = dict(linestyle='--', linewidth=0.5, color=colors[model_idx])\n",
    "        meanpointprops = dict(marker='o', markeredgecolor='black',\n",
    "                              markerfacecolor=colors[model_idx])\n",
    "        meanprops = dict(linestyle='-', linewidth=0.5, color=colors[model_idx])\n",
    "        data = mean_curvatures[model_idx, :, :].reshape(-1)\n",
    "        axs[data_idx].boxplot(data, sym='', positions=[model_idx], whis=(5, 95), widths=bar_width, meanline=True, showmeans=True, boxprops=boxprops,\n",
    "            whiskerprops=whiskerprops, capprops=capprops, medianprops=medianprops, meanprops=meanprops)\n",
    "    axs[data_idx].set_xticks([0, 1], minor=False)\n",
    "    axs[data_idx].set_xticks([], minor=True)\n",
    "    axs[data_idx].set_xticklabels(['Naturally trained', 'Adversarially trained'])\n",
    "    if data_idx == 0:\n",
    "        axs[data_idx].set_ylabel('Mean curvature')\n",
    "        axs[data_idx].set_title('Paired image boundary')\n",
    "    else:\n",
    "        axs[data_idx].set_title('Adversarial image boundary')\n",
    "fig.suptitle(f'Curvature at the decision boundary\\nfor the {num_images} images and the first {num_advs} adversarial directions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mean vs dim number\n",
    "colors = ['blue', 'orange']\n",
    "bar_width = 0.5\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, sharey=True)\n",
    "for data_idx in range(2):\n",
    "    mean_curvatures = [paired_mean_curvatures, adv_mean_curvatures][data_idx]\n",
    "    for model_idx in range(mean_curvatures.shape[0]):\n",
    "        boxprops = dict(color=colors[model_idx], linewidth=1.5, alpha=0.7)\n",
    "        whiskerprops = dict(color=colors[model_idx], alpha=0.7)\n",
    "        capprops = dict(color=colors[model_idx], alpha=0.7)\n",
    "        medianprops = dict(linestyle='--', linewidth=0.5, color=colors[model_idx])\n",
    "        meanpointprops = dict(marker='o', markeredgecolor='black',\n",
    "                              markerfacecolor=colors[model_idx])\n",
    "        meanprops = dict(linestyle='-', linewidth=0.5, color=colors[model_idx])\n",
    "        for adv_idx in range(mean_curvatures.shape[-1]):\n",
    "            data = mean_curvatures[model_idx, :, adv_idx].reshape(-1)\n",
    "            axs[data_idx].boxplot(data, sym='', positions=[adv_idx], whis=(5, 95), widths=bar_width, meanline=True, showmeans=True, boxprops=boxprops,\n",
    "                whiskerprops=whiskerprops, capprops=capprops, medianprops=medianprops, meanprops=meanprops)\n",
    "    if data_idx == 0:\n",
    "        axs[data_idx].set_ylabel('Mean curvature')\n",
    "        axs[data_idx].set_title('Paired image boundary')\n",
    "    else:\n",
    "        axs[data_idx].set_title('Adversarial image boundary')\n",
    "    axs[data_idx].set_xlabel('Dimension number')\n",
    "    axs[data_idx].set_xticks([i for i in range(mean_curvatures.shape[-1])], minor=False)\n",
    "    axs[data_idx].set_xticks([], minor=True)\n",
    "    axs[data_idx].set_xticklabels([str(i) for i in range(mean_curvatures.shape[-1])])\n",
    "fig.suptitle(f'Curvature at the decision boundary for {num_images} images and the first {num_advs} adversarial directions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
