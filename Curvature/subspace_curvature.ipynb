{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, './..')\n",
    "sys.path.insert(0, '../data')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import matplotlib.gridspec as gridspec\n",
    "import proplot as pplt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from models import eval\n",
    "from models import model as model_loader\n",
    "import plots as pl\n",
    "from utils import dev, load_data, classification\n",
    "\n",
    "sys.path.insert(0, './../../')\n",
    "\n",
    "import response_contour_analysis.utils.model_handling as model_utils\n",
    "import response_contour_analysis.utils.dataset_generation as data_utils\n",
    "import response_contour_analysis.utils.histogram_analysis as hist_utils\n",
    "import response_contour_analysis.utils.principal_curvature as curve_utils\n",
    "import response_contour_analysis.utils.plotting as plot_utils\n",
    "\n",
    "# check device\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment_params = dict()\n",
    "\n",
    "#experiment_params['target_model_id'] = 0\n",
    "#experiment_params['data_shape'] = images_nat[0,...].shape\n",
    "#experiment_params['window_scale'] = 2.0\n",
    "#experiment_params['num_edge_images'] = 30\n",
    "#experiment_params['target'] = 0.0\n",
    "#experiment_params['target_is_act'] = True\n",
    "\n",
    "#experiment_params['num_images'] = int(experiment_params['num_edge_images']**2)\n",
    "#experiment_params['x_range'] = (-experiment_params['window_scale'], experiment_params['window_scale'])\n",
    "#experiment_params['y_range'] = experiment_params['x_range']\n",
    "#experiment_params['device'] = DEVICE\n",
    "#yx_range = experiment_params['yx_range'] = (experiment_params['y_range'], experiment_params['x_range'])\n",
    "\n",
    "hess_params = dict()\n",
    "hess_params['hessian_num_pts'] = 1e3#5e3\n",
    "hess_params['hessian_lr'] = 1e-3\n",
    "hess_params['hessian_random_walk'] = False\n",
    "hess_params['return_points'] = False\n",
    "num_iters = 2 # for paired image boundary search\n",
    "num_steps_per_iter = 100 # for paired image boundary search\n",
    "buffer_portion = 0.25\n",
    "num_eps = 1000\n",
    "batch_size = 1000\n",
    "num_images = 5#50#labels_nat.size\n",
    "hess_radius_mult = 0.5\n",
    "num_advs = 4#8\n",
    "autodiff = False\n",
    "load = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data & models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "# load data\n",
    "data_natural = np.load(f'../data/natural_{seed}.npy', allow_pickle=True).item()\n",
    "advs_nat = data_natural['advs']\n",
    "pert_lengths_nat = data_natural['pert_lengths']\n",
    "classes_nat = data_natural['adv_class']\n",
    "dirs_nat = data_natural['dirs']\n",
    "images_nat = data_natural['images']\n",
    "labels_nat = data_natural['labels']\n",
    "\n",
    "data_madry = np.load(f'../data/robust_{seed}.npy', allow_pickle=True).item()\n",
    "advs_madry = data_madry['advs']\n",
    "pert_lengths_madry = data_madry['pert_lengths']\n",
    "classes_madry = data_madry['adv_class']\n",
    "dirs_madry = data_madry['dirs']\n",
    "images_madry = data_madry['images']\n",
    "labels_madry = data_madry['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pert_lengths = np.mean([pert_lengths_nat[np.isfinite(pert_lengths_nat)].mean(),\n",
    "                             pert_lengths_madry[np.isfinite(pert_lengths_madry)].mean()])\n",
    "hess_params['hessian_dist'] = mean_pert_lengths * hess_radius_mult # radius around the target image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models (all data assumes you are using the _diff model)\n",
    "model_natural = model_loader.madry_diff()\n",
    "model_madry = model_loader.madry_diff()\n",
    "model_random = model_loader.madry_diff()\n",
    "#if autodiff:\n",
    "#    model_natural = model_loader.madry_diff()\n",
    "#    model_madry = model_loader.madry_diff()\n",
    "#    model_random = model_loader.madry_diff()\n",
    "#else:\n",
    "#    model_natural = model_loader.madry()\n",
    "#    model_madry = model_loader.madry()\n",
    "#    model_random = model_loader.madry()\n",
    "\n",
    "model_natural.load_state_dict(torch.load(f'./../models/natural_{seed}.pt', map_location=DEVICE))\n",
    "model_natural.to(DEVICE)\n",
    "\n",
    "model_madry.load_state_dict(torch.load(f'./../models/robust_{seed}.pt', map_location=DEVICE))\n",
    "model_madry.to(DEVICE)\n",
    "\n",
    "model_random.load_state_dict(torch.load('./../models/random.pt', map_location=DEVICE))\n",
    "model_random.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plane curvature for one pair of dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_boundary_image(origin, eps=0.01, max_dist=4):\n",
    "    num_channels, num_rows, num_cols = origin.shape\n",
    "    direction = random_vector(num_channels * num_rows * num_cols)\n",
    "    correct_label = torch.argmax(model(origin))\n",
    "    pert_label = correct_label.clone()\n",
    "    pert_image = origin.clone()\n",
    "    num_steps = 0\n",
    "    while pert_label == correct_label:\n",
    "        pert_image = pert_image + direction * eps\n",
    "        pert_label = torch.argmax(model(pert_image))\n",
    "        num_steps += 1\n",
    "    pert_image = origin + num_steps-1 * direction * eps\n",
    "    small_eps = eps * 0.01\n",
    "    num_small_steps = 0\n",
    "    while pert_label == correct_label:\n",
    "        pert_image = pert_image + direction * small_eps\n",
    "        pert_label = torch.argmax(model(pert_image))\n",
    "        num_small_steps += 1\n",
    "    return pert_image\n",
    "    \n",
    "\n",
    "def random_vector(size):\n",
    "    components = [np.random.normal() for i in range(size)]\n",
    "    radius = np.sqrt(sum(x**2 for x in components))\n",
    "    vect = np.array([x/radius for x in components])\n",
    "    return vect\n",
    "\n",
    "\n",
    "def get_adv_boundary_image(model, origin, direction, length, origin_class, adv_class, num_eps, buffer_portion, batch_size, autodiff):\n",
    "    linspace_min = buffer_portion * length\n",
    "    linspace_max = (1 + buffer_portion) * length\n",
    "    eps_vals = np.linspace(linspace_min, linspace_max, num_eps)\n",
    "    direction = direction.reshape(1, direction.size)\n",
    "    eps_vals = eps_vals.reshape(-1, 1)\n",
    "    origin = origin.reshape(1, origin.size)\n",
    "    adv_line = origin + (direction * eps_vals)\n",
    "    adv_line = adv_line.reshape(-1, 1, int(np.sqrt(origin.size)), int(np.sqrt(origin.size)))\n",
    "    num_batches = int(np.ceil(num_eps / batch_size))\n",
    "    input_batches = torch.split(torchify(adv_line), num_batches)\n",
    "    model_outputs = np.empty((0, 10))\n",
    "    for batch in input_batches:\n",
    "        batch_outputs = model(batch).detach().cpu().numpy()\n",
    "        model_outputs = np.concatenate((model_outputs, batch_outputs), axis=0)\n",
    "    decision_scores = model_outputs[:, int(origin_class)] - model_outputs[:, int(adv_class)]\n",
    "    boundary_index = np.abs(decision_scores).argmin()\n",
    "    boundary_image = adv_line[boundary_index]\n",
    "    return boundary_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torchify(img):\n",
    "    output = torch.from_numpy(img).type(torch.DoubleTensor).to(DEVICE) # always autodiff\n",
    "    #if autodiff:\n",
    "    #    output = torch.from_numpy(img).type(torch.DoubleTensor).to(DEVICE)\n",
    "    #else:\n",
    "    #    output = torch.from_numpy(img).type(torch.FloatTensor).to(DEVICE)\n",
    "    return output\n",
    "\n",
    "\n",
    "def get_paired_boundary_image(model, origin, alt_image, num_steps_per_iter, num_iters):\n",
    "    num_channels, num_rows, num_cols = origin.shape\n",
    "    input_shape = [1, num_channels, num_rows, num_cols]\n",
    "    #correct_lbl = torch.argmax(model(torchify(origin.reshape(input_shape))))\n",
    "    #final_lbl = torch.argmax(model(torchify(alt_image.reshape(input_shape))))\n",
    "    #assert correct_lbl != final_lbl, (f'correct_lbl={correct_lbl}; final_lbl={final_lbl}')\n",
    "    \n",
    "    def find_pert(image_line):\n",
    "        correct_lbl = torch.argmax(model(torchify(image_line[0, ...].reshape(input_shape))))\n",
    "        pert_lbl = correct_lbl.clone()\n",
    "        step_idx = 1 # already know the first one\n",
    "        while pert_lbl == correct_lbl:\n",
    "            pert_image = image_line[step_idx, ...]\n",
    "            pert_lbl = torch.argmax(model(torchify(pert_image.reshape(input_shape))))\n",
    "            step_idx += 1\n",
    "        return step_idx-1, pert_image\n",
    "    \n",
    "    image_line = np.linspace(origin.reshape(-1), alt_image.reshape(-1), num_steps_per_iter)\n",
    "    for search_iter in range(num_iters):\n",
    "        step_idx, pert_image = find_pert(image_line)\n",
    "        image_line = np.linspace(image_line[step_idx - 1, ...], image_line[step_idx, ...], num_steps_per_iter)\n",
    "    delta_image = origin.reshape(-1) - pert_image\n",
    "    pert_length = np.linalg.norm(delta_image)\n",
    "    direction = delta_image / pert_length\n",
    "    return pert_image.reshape(origin.shape), direction, pert_length\n",
    "\n",
    "\n",
    "def generate_paired_dict(data_dict, model, num_images, num_advs):\n",
    "    image_shape = data_dict['images'].shape[1:]\n",
    "    num_pixels = int(np.prod(image_shape))\n",
    "    images = np.zeros((num_images,) + image_shape)\n",
    "    labels = np.zeros((num_images), dtype=np.int)\n",
    "    dirs = np.zeros((num_images, num_advs, 1, num_pixels))\n",
    "    advs = np.zeros((num_images, num_advs, 1, num_pixels))\n",
    "    pert_lengths = np.zeros((num_images, num_advs))\n",
    "    adv_class = np.zeros((num_images, num_advs))\n",
    "    model_predictions = torch.argmax(model(torchify(data_dict['images'])), dim=1).detach().cpu().numpy()\n",
    "    valid_indices = []\n",
    "    for image_idx in range(data_dict['images'].shape[0]):\n",
    "        if model_predictions[image_idx] == data_dict['labels'][image_idx]:\n",
    "            valid_indices.append(image_idx)\n",
    "    origin_indices = np.random.choice(valid_indices, size=num_images, replace=False)\n",
    "    for image_idx, origin_idx in enumerate(origin_indices):\n",
    "        images[image_idx, ...] = data_dict['images'][origin_idx, ...]\n",
    "        labels[image_idx] = data_dict['labels'][origin_idx]\n",
    "        shuffled_valid_indices = np.random.choice(valid_indices, size=len(valid_indices), replace=False)\n",
    "        alt_indices = [idx for idx, alt_class in zip(shuffled_valid_indices, data_dict['labels'][shuffled_valid_indices]) if alt_class != labels[image_idx]]\n",
    "        for dir_idx, alt_idx in enumerate(alt_indices[:num_advs]):\n",
    "            alt_image = data_dict['images'][alt_idx, ...]\n",
    "            boundary_image, boundary_dir, pert_length = get_paired_boundary_image(\n",
    "                model, images[image_idx, ...], alt_image, num_steps_per_iter, num_iters)\n",
    "            dirs[image_idx, dir_idx, ...] = boundary_dir.reshape(1, -1)\n",
    "            advs[image_idx, dir_idx, ...] = boundary_image.reshape(1, -1)\n",
    "            adv_class[image_idx,  dir_idx] = torch.argmax(model(torchify(boundary_image[None, ...]))).item()\n",
    "            pert_lengths[image_idx, dir_idx] =  pert_length\n",
    "    output_dict = {}\n",
    "    output_dict['images'] = images\n",
    "    output_dict['labels'] = labels\n",
    "    output_dict['dirs'] = dirs\n",
    "    output_dict['advs'] = advs\n",
    "    output_dict['adv_class'] = adv_class\n",
    "    output_dict['pert_lengths'] = pert_lengths\n",
    "    return output_dict\n",
    "\n",
    "\n",
    "def paired_activation(model, image, neuron1, neuron2):\n",
    "    if not image.requires_grad:\n",
    "        image.requires_grad = True\n",
    "    model.zero_grad()\n",
    "    activation1 = model_utils.unit_activation(model, image, neuron1, compute_grad=True)\n",
    "    activation2 = model_utils.unit_activation(model, image, neuron2, compute_grad=True)\n",
    "    activation_difference = activation1 - activation2\n",
    "    return activation_difference\n",
    "\n",
    "\n",
    "def paired_activation_and_gradient(model, image, neuron1, neuron2):\n",
    "    activation_difference = paired_activation(model, image, neuron1, neuron2)\n",
    "    grad = torch.autograd.grad(activation_difference, image)[0]\n",
    "    return activation_difference, grad\n",
    "\n",
    "\n",
    "def get_curvature(condition_zip, num_images, num_advs, num_eps, batch_size, buffer_portion, autodiff=False):\n",
    "    \"\"\"\n",
    "    A note on the gradient of the difference in activations:\n",
    "        The gradient points in the direction of the origin from the boundary image.\n",
    "        Therefore, for large enough eps, origin - eps * grad/|grad| will reach the boundary; and boundary + eps * grad/|grad| will reach the origin \n",
    "    \"\"\"\n",
    "    models, model_data = zip(*condition_zip)\n",
    "    num_models = len(models)\n",
    "    image_shape = model_data[0]['images'][0,...][None,...].shape\n",
    "    image_size = np.prod(image_shape)\n",
    "    shape_operators = np.zeros((num_models, num_images, num_advs, image_size, image_size))\n",
    "    principal_curvatures = np.zeros((num_models, num_images, num_advs, image_size))\n",
    "    principal_directions = np.zeros((num_models, num_images, num_advs, image_size, image_size))\n",
    "    mean_curvatures = np.zeros((num_models, num_images, num_advs))\n",
    "    for model_idx, (model, data)  in enumerate(zip(models, model_data)):\n",
    "        model_predictions = torch.argmax(model(torchify(data['images'])), dim=1).detach().cpu().numpy()\n",
    "        valid_indices = [] # Need to ensure that all images are correctly labeled & have valid adversarial examples\n",
    "        for image_idx in range(data['images'].shape[0]):\n",
    "            if model_predictions[image_idx] == data['labels'][image_idx]: # correctly labeled\n",
    "                if np.all(np.isfinite(data['pert_lengths'][image_idx, :num_advs])): # enough adversaries found\n",
    "                    adv_predictions = data['advs']\n",
    "                    valid_indices.append(image_idx)\n",
    "        origin_indices = np.random.choice(valid_indices, size=num_images, replace=False)\n",
    "        pbar = tqdm(total=num_images, leave=False)\n",
    "        for image_idx, origin_idx in enumerate(origin_indices):\n",
    "            clean_lbl = int(data['labels'][origin_idx])\n",
    "            for adv_idx in range(num_advs):\n",
    "                #adv_lbl = int(torch.argmax(model(torchify(data['advs'][origin_idx, adv_idx, ...].reshape(image_shape)))))\n",
    "                #assert clean_lbl != adv_lbl, (f'get_curvature: clean_lbl={clean_lbl}, adv_lbl={adv_lbl}')\n",
    "                boundary_image = get_paired_boundary_image(\n",
    "                    model=model,\n",
    "                    origin=data['images'][origin_idx, ...],\n",
    "                    alt_image=data['advs'][origin_idx, adv_idx, ...],\n",
    "                    num_steps_per_iter=num_steps_per_iter,\n",
    "                    num_iters=num_iters\n",
    "                )[0]\n",
    "                adv_lbl = int(data['adv_class'][origin_idx, adv_idx])\n",
    "                activation, gradient = paired_activation_and_gradient(model, torchify(boundary_image[None,...]), clean_lbl, adv_lbl)\n",
    "                gradient = gradient.reshape(-1)\n",
    "                if autodiff:\n",
    "                    def func(x):\n",
    "                        acts_diff = paired_activation(model, x, clean_lbl, adv_lbl)\n",
    "                        return acts_diff\n",
    "                    hessian = torch.autograd.functional.hessian(func, torchify(boundary_image[None,...]))\n",
    "                    hessian = hessian.reshape((int(boundary_image.size), int(boundary_image.size)))\n",
    "                else:\n",
    "                    def func(x):\n",
    "                        acts_diff, grad = paired_activation_and_gradient(model, x, clean_lbl, adv_lbl)\n",
    "                        return acts_diff, grad\n",
    "                    torch_image = torchify(boundary_image[None,...])\n",
    "                    torch_image.requires_grad = True\n",
    "                    hessian = curve_utils.sr1_hessian(\n",
    "                        func, torch_image,\n",
    "                        distance=hess_params['hessian_dist'],\n",
    "                        n_points=hess_params['hessian_num_pts'],\n",
    "                        random_walk=hess_params['hessian_random_walk'],\n",
    "                        learning_rate=hess_params['hessian_lr'],\n",
    "                        return_points=False,\n",
    "                        progress=False)\n",
    "                curvature = curve_utils.local_response_curvature(gradient, hessian)\n",
    "                shape_operators[model_idx, image_idx, adv_idx, ...] = curvature[0].detach().cpu().numpy()\n",
    "                principal_curvatures[model_idx, image_idx, adv_idx, :] = curvature[1].detach().cpu().numpy()\n",
    "                principal_directions[model_idx, image_idx, adv_idx, ...] = curvature[2].detach().cpu().numpy()\n",
    "                mean_curvatures[model_idx, image_idx, adv_idx] = np.mean(curvature[1].detach().cpu().numpy())\n",
    "            pbar.update(1)\n",
    "        pbar.close()\n",
    "    return shape_operators, principal_curvatures, principal_directions, mean_curvatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_and_data(data_nat, data_mad):\n",
    "    diff_str = '_diff' if autodiff else '_nodiff'\n",
    "    for model, data, name in zip([model_natural, model_madry], [data_nat, data_mad], ['natural'+diff_str, 'madry'+diff_str]):\n",
    "        image_shape = data['images'][0,...].shape\n",
    "        clean_count = 0\n",
    "        adv_count = 0\n",
    "        clean_imgs = torchify(data['images'])\n",
    "        clean_model_predictions = torch.argmax(model(clean_imgs), dim=1).detach().cpu().numpy()\n",
    "        for img_idx in range(data['images'].shape[0]):\n",
    "            label = int(data['labels'][img_idx])\n",
    "            prediction = int(clean_model_predictions[img_idx])\n",
    "            #assert  prediction == label , f'{name}: img_idx={img_idx}; prediction={prediction}; label={label}'\n",
    "            #if clean_model_predictions[img_idx] != data['labels'][img_idx]: print(f'{name}: img_idx={img_idx}; prediction={clean_model_predictions[img_idx]}; label={data[\"labels\"][img_idx]}')\n",
    "            if clean_model_predictions[img_idx] != data['labels'][img_idx]: clean_count += 1\n",
    "            adv_imgs = torchify(data['advs'][img_idx, ...].reshape((-1,)+image_shape))\n",
    "            adv_model_predictions = torch.argmax(model(adv_imgs), dim=1).detach().cpu().numpy()\n",
    "            for adv_idx in range(data['adv_class'].shape[1]):\n",
    "                if np.isfinite(data['pert_lengths'][img_idx, adv_idx]):\n",
    "                    label = int(data['adv_class'][img_idx, adv_idx])\n",
    "                    prediction = int(adv_model_predictions[adv_idx])\n",
    "                    #assert  prediction == label, f'{name}: img_idx={img_idx}, adv_idx={adv_idx}, prediction={prediction}, adv_label={label}'\n",
    "                    #if adv_model_predictions[adv_idx] != data['adv_class'][img_idx, adv_idx]: print(f'{name}: img_idx={img_idx}, adv_idx={adv_idx}, prediction={adv_model_predictions[adv_idx]}, label={data[\"adv_class\"][img_idx, adv_idx]}')\n",
    "                    if adv_model_predictions[adv_idx] != data['adv_class'][img_idx, adv_idx]: adv_count += 1\n",
    "        print(f'{name}: number of clean images with bad predictions = {clean_count}; number of adv images with bad predictions = {adv_count}')\n",
    "\n",
    "#test_model_and_data(data_paired_natural, data_paired_madry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if autodiff:\n",
    "    filename = '../data/curvatures_and_directions_autodiff.npz'\n",
    "else:\n",
    "    filename = '../data/curvatures_and_directions_sr1.npz'\n",
    "\n",
    "if load:\n",
    "    data = np.load(filename, allow_pickle=True)['data'].item()\n",
    "    data_paired_natural = data['data_paired_natural']\n",
    "    data_paired_madry = data['data_paired_madry']\n",
    "    paired_shape_operators = data['paired_shape_operators']\n",
    "    paired_principal_curvatures = data['paired_principal_curvatures']\n",
    "    paired_principal_directions = data['paired_principal_directions']\n",
    "    paired_mean_curvatures = data['paired_mean_curvatures']\n",
    "    adv_shape_operators = data['adv_shape_operators']\n",
    "    adv_principal_curvatures = data['adv_principal_curvatures']\n",
    "    adv_principal_directions = data['adv_principal_directions']\n",
    "    adv_mean_curvatures = data['adv_mean_curvatures']\n",
    "else:\n",
    "    data_paired_natural = generate_paired_dict(data_natural, model_natural, num_images, num_advs)\n",
    "    data_paired_madry = generate_paired_dict(data_madry, model_madry, num_images, num_advs)\n",
    "    paired_condition_zip = zip([model_natural, model_madry], [data_paired_natural, data_paired_madry])\n",
    "    paired_shape_operators, paired_principal_curvatures, paired_principal_directions, paired_mean_curvatures = get_curvature(\n",
    "        paired_condition_zip, num_images, num_advs, num_eps, batch_size, buffer_portion, autodiff)\n",
    "    adv_condition_zip = zip([model_natural, model_madry], [data_natural, data_madry])\n",
    "    adv_shape_operators, adv_principal_curvatures, adv_principal_directions, adv_mean_curvatures = get_curvature(\n",
    "        adv_condition_zip, num_images, num_advs, num_eps, batch_size, buffer_portion, autodiff)\n",
    "    save_dict = {\n",
    "        'data_paired_natural':data_paired_natural,\n",
    "        'dat_paired_madry':data_paired_madry,\n",
    "        'paired_shape_operators': paired_shape_operators,\n",
    "        'paired_principal_curvatures': paired_principal_curvatures,\n",
    "        'paired_principal_directions': paired_principal_directions,\n",
    "        'paired_mean_curvatures': paired_mean_curvatures,\n",
    "        'adv_shape_operators': adv_shape_operators,\n",
    "        'adv_principal_curvatures': adv_principal_curvatures,\n",
    "        'adv_principal_directions': adv_principal_directions,\n",
    "        'adv_mean_curvatures': adv_mean_curvatures\n",
    "    }\n",
    "    np.savez(filename, data=save_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['blue', 'orange']\n",
    "bar_width = 0.5\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, sharey=True, figsize=(12,4))\n",
    "fig.subplots_adjust(top=0.8)\n",
    "\n",
    "for data_idx in range(2):\n",
    "    mean_curvatures = [paired_mean_curvatures, adv_mean_curvatures][data_idx]\n",
    "    for model_idx in range(2):\n",
    "        boxprops = dict(color=colors[model_idx], linewidth=1.5, alpha=0.7)\n",
    "        whiskerprops = dict(color=colors[model_idx], alpha=0.7)\n",
    "        capprops = dict(color=colors[model_idx], alpha=0.7)\n",
    "        medianprops = dict(linestyle='--', linewidth=0.5, color=colors[model_idx])\n",
    "        meanpointprops = dict(marker='o', markeredgecolor='black',\n",
    "                              markerfacecolor=colors[model_idx])\n",
    "        meanprops = dict(linestyle='-', linewidth=0.5, color=colors[model_idx])\n",
    "        data = mean_curvatures[model_idx, :, :].reshape(-1)\n",
    "        axs[data_idx].boxplot(data, sym='', positions=[model_idx], whis=(5, 95), widths=bar_width, meanline=True, showmeans=True, boxprops=boxprops,\n",
    "            whiskerprops=whiskerprops, capprops=capprops, medianprops=medianprops, meanprops=meanprops)\n",
    "    axs[data_idx].set_xticks([0, 1], minor=False)\n",
    "    axs[data_idx].set_xticks([], minor=True)\n",
    "    axs[data_idx].set_xticklabels(['Naturally trained', 'Adversarially trained'])\n",
    "    if data_idx == 0:\n",
    "        axs[data_idx].set_ylabel('Mean curvature')\n",
    "        axs[data_idx].set_title('Paired image boundary')\n",
    "    else:\n",
    "        axs[data_idx].set_title('Adversarial image boundary')\n",
    "\n",
    "for model_idx in range(adv_mean_curvatures.shape[0]):\n",
    "    boxprops = dict(color=colors[model_idx], linewidth=1.5, alpha=0.7)\n",
    "    whiskerprops = dict(color=colors[model_idx], alpha=0.7)\n",
    "    capprops = dict(color=colors[model_idx], alpha=0.7)\n",
    "    medianprops = dict(linestyle='--', linewidth=0.5, color=colors[model_idx])\n",
    "    meanpointprops = dict(marker='o', markeredgecolor='black',\n",
    "                          markerfacecolor=colors[model_idx])\n",
    "    meanprops = dict(linestyle='-', linewidth=0.5, color=colors[model_idx])\n",
    "    for adv_idx in range(adv_mean_curvatures.shape[-1]):\n",
    "        data = adv_mean_curvatures[model_idx, :, adv_idx].reshape(-1)\n",
    "        axs[2].boxplot(data, sym='', positions=[adv_idx], whis=(5, 95), widths=bar_width, meanline=True, showmeans=True, boxprops=boxprops,\n",
    "            whiskerprops=whiskerprops, capprops=capprops, medianprops=medianprops, meanprops=meanprops)\n",
    "axs[2].set_title('Adversarial image boundary')\n",
    "axs[2].set_xlabel('Dimension number')\n",
    "axs[2].set_xticks([i for i in range(adv_mean_curvatures.shape[-1])], minor=False)\n",
    "axs[2].set_xticks([], minor=True)\n",
    "axs[2].set_xticklabels([str(i+1) for i in range(adv_mean_curvatures.shape[-1])])\n",
    "\n",
    "def make_space_above(axes, topmargin=1):\n",
    "    \"\"\" increase figure size to make topmargin (in inches) space for \n",
    "        titles, without changing the axes sizes\"\"\"\n",
    "    fig = axes.flatten()[0].figure\n",
    "    s = fig.subplotpars\n",
    "    w, h = fig.get_size_inches()\n",
    "\n",
    "    figh = h - (1-s.top)*h  + topmargin\n",
    "    fig.subplots_adjust(bottom=s.bottom*h/figh, top=1-topmargin/figh)\n",
    "    fig.set_figheight(figh)\n",
    "\n",
    "\n",
    "make_space_above(axs, topmargin=0.5)  \n",
    "\n",
    "fig.suptitle(f'Curvature at the decision boundary\\nfor {num_images} images and the first {num_advs} adversarial directions', y=1.0)\n",
    "plt.show()\n",
    "fig.savefig('../data/mean_curvature_boxplots.png', transparent=True, bbox_inches=\"tight\", pad_inches=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curvature_indices = [0, 10, 100, -100, -10, -1]\n",
    "#curvature_indices = [-100]\n",
    "\n",
    "matrix_shape = adv_principal_curvatures.shape[1:3]\n",
    "(image_idx, adv_idx) = [np.random.randint(low=0, high=matrix_shape[i]) for i in range(len(matrix_shape))]\n",
    "while not np.isfinite(data_natural['pert_lengths'][image_idx, adv_idx]):\n",
    "    (image_idx, adv_idx) = [np.random.randint(low=0, high=matrix_shape[i]) for i in range(len(matrix_shape))]\n",
    "origin = data_natural['images'][image_idx, ...]#.reshape(-1)\n",
    "\n",
    "boundary_image = get_paired_boundary_image(\n",
    "    model=model_natural,\n",
    "    origin=origin,\n",
    "    alt_image=data_natural['advs'][image_idx, adv_idx, ...],\n",
    "    num_steps_per_iter=num_steps_per_iter,\n",
    "    num_iters=num_iters\n",
    ")[0]\n",
    "boundary_dist = np.linalg.norm(boundary_image.reshape(-1) - origin.reshape(-1))\n",
    "\n",
    "figsize = 8\n",
    "fig, axs = plt.subplots(nrows=len(curvature_indices), ncols=1, figsize=(figsize, figsize*len(curvature_indices)))\n",
    "for ax_idx, curvature_idx in enumerate(curvature_indices):\n",
    "    ax = axs[ax_idx]\n",
    "    random_index = (0, image_idx, adv_idx, curvature_idx, Ellipsis)\n",
    "    adv1 = boundary_image.reshape(-1)\n",
    "    adv2 = origin.reshape(-1) + boundary_dist * adv_principal_directions[random_index]\n",
    "    model_ = model_natural\n",
    "    pl.plot_dec_space(origin, adv1, adv2, model_, offset=1, n_grid=100, show_legend=True, show_advs=True, overlay_inbounds=True, ax=ax)\n",
    "    ax.set_title(f'Curvature = {adv_principal_curvatures[random_index]:.5f}')\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('../data/curvature_visualizations.png', transparent=True, bbox_inches=\"tight\", pad_inches=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('../data/adv_fig.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activation, gradient = model_utils.unit_activation_and_gradient(model_natural, torchify(boundary_image[None,...]), clean_id)\n",
    "#gradient = gradient.reshape(-1)\n",
    "#abscissa = [gradient]\n",
    "#ordinate = [adv_principal_directions[random_index]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
